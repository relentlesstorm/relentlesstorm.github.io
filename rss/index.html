<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[FlamingBytes]]></title><description><![CDATA[Stay hungry, Stay foolish.]]></description><link>https://www.flamingbytes.com/</link><image><url>https://www.flamingbytes.com/favicon.png</url><title>FlamingBytes</title><link>https://www.flamingbytes.com/</link></image><generator>Ghost 5.26</generator><lastBuildDate>Tue, 14 Feb 2023 05:24:19 GMT</lastBuildDate><atom:link href="https://www.flamingbytes.com/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[YCSB benchmark on PostgreSQL]]></title><description><![CDATA[go-ycsb is a Go port of YCSB. It fully supports all YCSB generators and the Core workload so we can do the basic CRUD benchmarks with Go.]]></description><link>https://www.flamingbytes.com/blog/ycsb-benchmark-on-postgresql/</link><guid isPermaLink="false">63eb1767361c0d0ddf89fbef</guid><category><![CDATA[Benchmarking]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Tue, 14 Feb 2023 05:20:50 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1533284133567-0da9844151ce?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDl8fHJhY2V8ZW58MHx8fHwxNjc2MzUxODY1&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><h2 id="create-a-postgresql-database">Create a PostgreSQL database</h2>
<img src="https://images.unsplash.com/photo-1533284133567-0da9844151ce?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDl8fHJhY2V8ZW58MHx8fHwxNjc2MzUxODY1&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="YCSB benchmark on PostgreSQL"><p>You can follow this <a href="https://www.flamingbytes.com/blog/getting-started-with-postgresql/">post</a> to install PostgreSQL and create the database cluster.</p>
<p><strong>To create a database:</strong></p>
<pre><code>$ db_host=10.10.10.243; db_port=5432; db_user=postgres; db_name=testdb

$ psql --host=$db_host --port=$db_port --username=$db_user -w -c &quot;create database $db_name&quot;
$ psql --host=$db_host --port=$db_port --username=$db_user -w -c &quot;\l&quot;
$ psql --host=$db_host --port=$db_port --username=$db_user -w -d $db_name -c &quot;\dt+&quot;
</code></pre>
<h2 id="load-data-to-database">Load data to database</h2>
<p><a href="https://github.com/pingcap/go-ycsb">go-ycsb</a> is a Go port of YCSB. It fully supports all YCSB generators and the Core workload so we can do the basic CRUD benchmarks with Go.</p>
<pre><code>$ ./bin/go-ycsb load postgresql -P workloads/workloadd --threads 768 -p pg.host=$db_host -p pg.port=$db_port -p pg.user=$db_user -p pg.db=$db_name -p pg.sslmode=disable -p dropdata=true
&lt;snippet&gt;
Run finished, takes 29m39.847077518s
INSERT - Takes(s): 1779.8, Count: 97404992, OPS: 54727.5, Avg(us): 11176, Min(us): 179, Max(us): 80767, 99th(us): 72127, 99.9th(us): 79807, 99.99th(us): 80703
</code></pre>
<h2 id="run-ycsb-benchmark">Run YCSB benchmark</h2>
<pre><code>$ ./bin/go-ycsb run postgresql -P workloads/workloadd --threads 768 -p pg.host=$db_host -p pg.port=$db_port -p pg.user=$db_user -p pg.db=$db_name -p pg.sslmode=disable
&lt;snippet&gt;
Run finished, takes 14m8.828228178s
INSERT - Takes(s): 848.8, Count: 4981537, OPS: 5868.8, Avg(us): 1968, Min(us): 226, Max(us): 19327, 99th(us): 11623, 99.9th(us): 17567, 99.99th(us): 19119
READ   - Takes(s): 848.8, Count: 93786269, OPS: 110492.3, Avg(us): 5899, Min(us): 78, Max(us): 41247, 99th(us): 32831, 99.9th(us): 40063, 99.99th(us): 41119
</code></pre>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://github.com/pingcap/go-ycsb">https://github.com/pingcap/go-ycsb</a></li>
</ul>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Getting started with PostgreSQL]]></title><description><![CDATA[PostgreSQL is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that safely store and scale the most complicated data workloads. ]]></description><link>https://www.flamingbytes.com/blog/getting-started-with-postgresql/</link><guid isPermaLink="false">63eb11f1361c0d0ddf89fb77</guid><category><![CDATA[Big Data]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Mon, 13 Feb 2023 05:02:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1489875347897-49f64b51c1f8?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fG15c3FsfGVufDB8fHx8MTY3NjM1MDkxOQ&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><h2 id="install-the-postgresql-from-yum-repository">Install the PostgreSQL from YUM repository</h2>
<img src="https://images.unsplash.com/photo-1489875347897-49f64b51c1f8?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fG15c3FsfGVufDB8fHx8MTY3NjM1MDkxOQ&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Getting started with PostgreSQL"><p><strong>Install the repository RPM:</strong></p>
<pre><code>$ yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm
</code></pre>
<p><strong>Install PostgreSQL:</strong></p>
<pre><code>$ yum install -y postgresql15-server
</code></pre>
<h2 id="create-a-database-cluster">Create a Database Cluster</h2>
<p>Before you can do anything, you must initialize a database storage area on disk. We call this a database cluster.</p>
<pre><code>$ su - postgres

-bash-4.2$ /usr/pgsql-15/bin/pg_ctl --help
pg_ctl is a utility to initialize, start, stop, or control a PostgreSQL server.

Usage:
  pg_ctl init[db]   [-D DATADIR] [-s] [-o OPTIONS]
  pg_ctl start      [-D DATADIR] [-l FILENAME] [-W] [-t SECS] [-s]
                    [-o OPTIONS] [-p PATH] [-c]
  pg_ctl stop       [-D DATADIR] [-m SHUTDOWN-MODE] [-W] [-t SECS] [-s]
  pg_ctl restart    [-D DATADIR] [-m SHUTDOWN-MODE] [-W] [-t SECS] [-s]
                    [-o OPTIONS] [-c]
  pg_ctl reload     [-D DATADIR] [-s]
  pg_ctl status     [-D DATADIR]
  pg_ctl promote    [-D DATADIR] [-W] [-t SECS] [-s]
  pg_ctl logrotate  [-D DATADIR] [-s]
  pg_ctl kill       SIGNALNAME PID

Common options:
  -D, --pgdata=DATADIR   location of the database storage area
  -s, --silent           only print errors, no informational messages
  -t, --timeout=SECS     seconds to wait when using -w option
  -V, --version          output version information, then exit
  -w, --wait             wait until operation completes (default)
  -W, --no-wait          do not wait until operation completes
  -?, --help             show this help, then exit
If the -D option is omitted, the environment variable PGDATA is used.

Options for start or restart:
  -c, --core-files       allow postgres to produce core files
  -l, --log=FILENAME     write (or append) server log to FILENAME
  -o, --options=OPTIONS  command line options to pass to postgres
                         (PostgreSQL server executable) or initdb
  -p PATH-TO-POSTGRES    normally not necessary

Options for stop or restart:
  -m, --mode=MODE        MODE can be &quot;smart&quot;, &quot;fast&quot;, or &quot;immediate&quot;

Shutdown modes are:
  smart       quit after all clients have disconnected
  fast        quit directly, with proper shutdown (default)
  immediate   quit without complete shutdown; will lead to recovery on restart

Allowed signal names for kill:
  ABRT HUP INT KILL QUIT TERM USR1 USR2

Report bugs to &lt;pgsql-bugs@lists.postgresql.org&gt;.
PostgreSQL home page: &lt;https://www.postgresql.org/&gt;
</code></pre>
<p><strong>Create the data directory:</strong></p>
<pre><code>$ mkdir -p /mnt/pgsql15/data
$ chown -R postgres /mnt/pgsql15
</code></pre>
<p><strong>Create the database cluster:</strong></p>
<pre><code>$ su - postgres -c &quot;/usr/pgsql-15/bin/initdb -D /mnt/pgsql15/data&quot;

$ ls /mnt/pgsql15/data
base log pg_dynshmem pg_ident.conf pg_multixact pg_replslot pg_snapshots  pg_stat_tmp pg_tblspc PG_VERSION pg_xact postgresql.conf
global pg_commit_ts pg_hba.conf pg_logical pg_notify pg_serial pg_stat pg_subtrans pg_twophase pg_wal postgresql.auto.conf
</code></pre>
<p><strong>Start and stop the database server:</strong></p>
<pre><code>-bash-4.2$ /usr/pgsql-15/bin/pg_ctl -D /mnt/pgsql15/data -l logfile start
waiting for server to start.... done
server started

-bash-4.2$ /usr/pgsql-15/bin/pg_ctl -D /mnt/pgsql15/data stop
waiting for server to shut down.... done
server stopped

-bash-4.2$ /usr/pgsql-15/bin/pg_ctl -D /mnt/pgsql15/data -l logfile start
waiting for server to start.... done
server started

-bash-4.2$ ls -ltr
total 4
drwx------ 4 postgres postgres  51 Feb 13 20:48 15
-rw------- 1 postgres postgres 374 Feb 13 22:26 logfile
</code></pre>
<p><strong>Restart the database server:</strong></p>
<pre><code>-bash-4.2$ /usr/pgsql-15/bin/pg_ctl -D /mnt/pgsql15/data -l logfile restart
waiting for server to shut down.... done
server stopped
waiting for server to start.... done
server started
</code></pre>
<p><strong>Check the database service:</strong></p>
<pre><code>-bash-4.2$ /usr/pgsql-15/bin/pg_ctl -D /mnt/pgsql15/data status
pg_ctl: server is running (PID: 77038)
/usr/pgsql-15/bin/postgres &quot;-D&quot; &quot;/mnt/pgsql15/data&quot;

-bash-4.2$ ps aux | grep postgres | grep -v grep
root     73095  0.0  0.0 191900  4348 pts/0    S    21:49   0:00 su - postgres
postgres 73096  0.0  0.0 115560  3456 pts/0    S    21:49   0:00 -bash
postgres 77434  0.1  0.0 401372 23652 ?        Ss   22:26   0:00 /usr/pgsql-15/bin/postgres -D /mnt/pgsql15/data
postgres 77435  0.0  0.0 253204  5692 ?        Ss   22:26   0:00 postgres: logger
postgres 77436  0.0  0.0 401524  5728 ?        Ss   22:26   0:00 postgres: checkpointer
postgres 77437  0.0  0.0 401508  5784 ?        Ss   22:26   0:00 postgres: background writer
postgres 77439  0.0  0.0 401508 10372 ?        Ss   22:26   0:00 postgres: walwriter
postgres 77440  0.0  0.0 402992  8864 ?        Ss   22:26   0:00 postgres: autovacuum launcher
postgres 77441  0.0  0.0 402976  6904 ?        Ss   22:26   0:00 postgres: logical replication launcher
postgres 77480  0.0  0.0 155468  3784 pts/0    R+   22:27   0:00 ps aux
</code></pre>
<h2 id="using-psql">Using psql</h2>
<p><a href="https://www.postgresql.org/docs/current/app-psql.html">psql</a> is a terminal-based front-end to PostgreSQL. It enables you to type in queries interactively, issue them to PostgreSQL, and see the query results. Alternatively, input can be from a file or from command line arguments. In addition, psql provides a number of meta-commands and various shell-like features to facilitate writing scripts and automating a wide variety of tasks.</p>
<p><strong>Create a database:</strong></p>
<pre><code>$ su - postgres
Last login: Mon Feb 13 20:12:36 UTC 2023 on pts/0

-bash-4.2$ psql
psql (15.2)
Type &quot;help&quot; for help.

postgres=# \l
                                                 List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    | ICU Locale | Locale Provider |   Access privileges
-----------+----------+----------+-------------+-------------+------------+-----------------+-----------------------
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            | =c/postgres          +
           |          |          |             |             |            |                 | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            | =c/postgres          +
           |          |          |             |             |            |                 | postgres=CTc/postgres
(3 rows)


postgres=# create database testdb;
CREATE DATABASE

postgres=# \l
                                                 List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    | ICU Locale | Locale Provider |   Access privileges
-----------+----------+----------+-------------+-------------+------------+-----------------+-----------------------
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            | =c/postgres          +
           |          |          |             |             |            |                 | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            | =c/postgres          +
           |          |          |             |             |            |                 | postgres=CTc/postgres
 testdb    | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            |
(4 rows)
</code></pre>
<p><strong>Drop database:</strong></p>
<pre><code>postgres=# drop database if exists testdb;
DROP DATABASE
postgres=# \l
                                                 List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    | ICU Locale | Locale Provider |   Access privileges
-----------+----------+----------+-------------+-------------+------------+-----------------+-----------------------
 postgres  | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            |
 template0 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            | =c/postgres          +
           |          |          |             |             |            |                 | postgres=CTc/postgres
 template1 | postgres | UTF8     | en_US.UTF-8 | en_US.UTF-8 |            | libc            | =c/postgres          +
           |          |          |             |             |            |                 | postgres=CTc/postgres
(3 rows)
</code></pre>
<p><strong>Manipulate the database remotely:</strong></p>
<pre><code>psql --host=10.13.121.243 --port=5432 --username=postgres -w -c &quot;create database testdb&quot;
psql --host=10.13.121.243 --port=5432 --username=postgres -w -c &quot;\l&quot;
psql --host=10.13.121.243 --port=5432 --username=postgres -w -d testdb -c &quot;\dt+&quot;
</code></pre>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://www.postgresql.org/download/linux/redhat/">https://www.postgresql.org/download/linux/redhat/</a></li>
<li><a href="https://www.postgresql.org/docs/15/creating-cluster.html">https://www.postgresql.org/docs/15/creating-cluster.html</a></li>
</ul>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Getting started with BCC (BPF Compiler Collection)]]></title><description><![CDATA[BCC is a toolkit for creating efficient kernel tracing and manipulation programs, and includes several useful tools and examples. ]]></description><link>https://www.flamingbytes.com/blog/getting-started-with-bcc/</link><guid isPermaLink="false">63e9a9a1f19d570e66aae077</guid><category><![CDATA[Performance]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Sun, 12 Feb 2023 03:40:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1661956602868-6ae368943878?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wxfDF8YWxsfDE2fHx8fHx8Mnx8MTY3NjI1NTU4OA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><h2 id="intro-to-bcc">Intro to BCC</h2>
<img src="https://images.unsplash.com/photo-1661956602868-6ae368943878?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wxfDF8YWxsfDE2fHx8fHx8Mnx8MTY3NjI1NTU4OA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Getting started with BCC (BPF Compiler Collection)"><p><a href="https://github.com/iovisor/bcc">BCC</a> is a toolkit for creating efficient kernel tracing and manipulation programs, and includes several useful tools and examples. It makes use of extended BPF (Berkeley Packet Filters), formally known as eBPF, a new feature that was first added to Linux 3.15. Much of what BCC uses requires Linux 4.1 and above.</p>
<h2 id="install-bcc-from-packages">Install BCC from packages</h2>
<p>In general, a Linux kernel version 4.1 or newer is required.</p>
<pre><code>$ cat /etc/centos-release
CentOS Linux release 7.9.2009 (Core)

$ uname -r
5.7.12-1.el7.elrepo.x86_64
</code></pre>
<p>In addition, the kernel should have been compiled with the following <a href="https://github.com/iovisor/bcc/blob/master/INSTALL.md">flags set</a>.</p>
<pre><code>CONFIG_BPF=y
CONFIG_BPF_SYSCALL=y
# [optional, for tc filters]
CONFIG_NET_CLS_BPF=m
# [optional, for tc actions]
CONFIG_NET_ACT_BPF=m
CONFIG_BPF_JIT=y
# [for Linux kernel versions 4.1 through 4.6]
CONFIG_HAVE_BPF_JIT=y
# [for Linux kernel versions 4.7 and later]
CONFIG_HAVE_EBPF_JIT=y
# [optional, for kprobes]
CONFIG_BPF_EVENTS=y
# Need kernel headers through /sys/kernel/kheaders.tar.xz
CONFIG_IKHEADERS=y
</code></pre>
<p>There are a few optional kernel flags needed for running bcc networking examples on vanilla kernel:</p>
<pre><code>CONFIG_NET_SCH_SFQ=m
CONFIG_NET_ACT_POLICE=m
CONFIG_NET_ACT_GACT=m
CONFIG_DUMMY=m
CONFIG_VXLAN=m
</code></pre>
<p>These kernel configuration might be set by default after the OS installation but you should double check as below.</p>
<pre><code>$ cat /boot/config-$(uname -r)
</code></pre>
<p><strong>To install the BCC tools from the official yum repository:</strong></p>
<pre><code>$ yum install bcc-tools
Installed:
  bcc-tools.x86_64 0:0.10.0-1.el7

Dependency Installed:
  bcc.x86_64 0:0.10.0-1.el7   python-bcc.x86_64 0:0.10.0-1.el7
</code></pre>
<p>The following BCC tools are pre-defined and available to use after installation.</p>
<pre><code>$ cd /usr/share/bcc
$ ls
introspection  tools
$ cd /usr/share/bcc/tools
$ ls
argdist bpflist cobjnew dcstat ext4dist funclatency javagc llcstat nfsslower opensnoop phpstat pythonstat rubystat sofdsnoop syncsnoop tcpaccept tcpsubnet vfscount bashreadline btrfsdist cpudist deadlock ext4slower funcslower javaobjnew mdflush nodegc perlcalls  pidpersec reset-trace runqlat softirqs syscount tcpconnect tcptop vfsstat biolatency btrfsslower cpuunclaimed deadlock.c filelife gethostlatency  javastat memleak nodestat perlflow profile rubycalls runqlen solisten tclcalls tcpconnlat tcptracer wakeuptime biosnoop cachestat dbslower doc fileslower hardirqs javathreads mountsnoop offcputime perlstat pythoncalls rubyflow runqslower sslsniff tclflow tcpdrop tplist xfsdist biotop cachetop dbstat drsnoop filetop javacalls killsnoop mysqld_qslower offwaketime phpcalls pythonflow rubygc shmsnoop stackcount tclobjnew tcplife trace xfsslower bitesize capable dcsnoop execsnoop funccount javaflow lib nfsdist oomkill phpflow pythongc rubyobjnew slabratetop statsnoop tclstat tcpretrans ttysnoop
</code></pre>
<p><strong>To add bcc directory to the $PATH:</strong></p>
<pre><code>$ vim .bash_profile
bcctools=/usr/share/bcc/tools
PATH=$PATH:$HOME/bin:$bcctools
export PATH
    
$ source ~/.bash_profile
$ echo $PATH
/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/root/bin:/usr/share/bcc/tools
</code></pre>
<h2 id="install-bcc-from-source">Install BCC from source</h2>
<p>If you want to install a different version of BCC, you can refer to <a href="https://github.com/iovisor/bcc/blob/master/INSTALL.md">here</a>. I tried this but it seems very tricky to install it successfully. I&apos;ll not discuss it in this post.</p>
<h2 id="use-the-bcc-tools">Use the BCC tools</h2>
<p>It&apos;s not suprise if you see the following error for the first time run of BCC tools.</p>
<pre><code>$ biolatency
In file included from /virtual/main.c:2:
In file included from /lib/modules/5.7.12-1.el7.elrepo.x86_64/build/include/uapi/linux/ptrace.h:142:
In file included from /lib/modules/5.7.12-1.el7.elrepo.x86_64/build/arch/x86/include/asm/ptrace.h:5:
/lib/modules/5.7.12-1.el7.elrepo.x86_64/build/arch/x86/include/asm/segment.h:266:2: error: expected &apos;(&apos; after &apos;asm&apos;
        alternative_io (&quot;lsl %[seg],%[p]&quot;,
        ^
/lib/modules/5.7.12-1.el7.elrepo.x86_64/build/arch/x86/include/asm/alternative.h:240:2: note: expanded from macro &apos;alternative_io&apos;
        asm_inline volatile (ALTERNATIVE(oldinstr, newinstr, feature)   \
        ^
/lib/modules/5.7.12-1.el7.elrepo.x86_64/build/include/linux/compiler_types.h:201:24: note: expanded from macro &apos;asm_inline&apos;
#define asm_inline asm __inline
                       ^
In file included from /virtual/main.c:3:
</code></pre>
<p>This is because many BCC tools are broken with kernel 5.4+ and libbcc 0.10.</p>
<p><strong>To fix this problem:</strong></p>
<p>Modify as below for the BPF program definition.</p>
<p>Original code:</p>
<pre><code>$ vim biolatency
&lt;snippet&gt;
# define BPF program
bpf_text = &quot;&quot;&quot;
#include &lt;uapi/linux/ptrace.h&gt;
#include &lt;linux/blkdev.h&gt;
&lt;snippet&gt;
</code></pre>
<p>Modified code:</p>
<pre><code>$ vim biolatency
&lt;snippet&gt;
# define BPF program
bpf_text = &quot;&quot;&quot;
#ifdef asm_inline
#undef asm_inline
#define asm_inline asm
#endif
#include &lt;uapi/linux/ptrace.h&gt;
#include &lt;linux/blkdev.h&gt;
&lt;snippet&gt;
</code></pre>
<p><strong>Run the BCC tool again now:</strong></p>
<pre><code>$ biolatency
Tracing block device I/O... Hit Ctrl-C to end.
^C
    usecs               : count     distribution
    0 -&gt; 1          : 0        |                                        |
    2 -&gt; 3          : 0        |                                        |
    4 -&gt; 7          : 0        |                                        |
    8 -&gt; 15         : 0        |                                        |
    16 -&gt; 31        : 0        |                                        |
    32 -&gt; 63        : 6        |********************                    |
    64 -&gt; 127       : 12       |****************************************|
    128 -&gt; 255      : 3        |**********                              |
</code></pre>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://github.com/iovisor/bcc">https://github.com/iovisor/bcc</a></li>
<li><a href="https://blogs.oracle.com/linux/post/intro-to-bcc-1">https://blogs.oracle.com/linux/post/intro-to-bcc-1</a></li>
<li><a href="https://gitlab.com/gitlab-com/gl-infra/reliability/-/issues/12052">https://gitlab.com/gitlab-com/gl-infra/reliability/-/issues/12052</a></li>
<li><a href="https://blog.csdn.net/thesre/article/details/122508493">https://blog.csdn.net/thesre/article/details/122508493</a></li>
<li><a href="https://www.containiq.com/post/bcc-tools">https://www.containiq.com/post/bcc-tools</a></li>
</ul>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Install GCC from source]]></title><description><![CDATA[In this post, we will go through the steps to install GCC.]]></description><link>https://www.flamingbytes.com/blog/install-gcc-from-source/</link><guid isPermaLink="false">63e9a08bf19d570e66aae054</guid><category><![CDATA[Linux]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Fri, 10 Feb 2023 02:33:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1675959449383-1c7a27684c3c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8YWxsfDJ8fHx8fHwyfHwxNjc2MjU1NTg4&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="https://images.unsplash.com/photo-1675959449383-1c7a27684c3c?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8YWxsfDJ8fHx8fHwyfHwxNjc2MjU1NTg4&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Install GCC from source"><p>In this post, we will go through the steps to install <a href="https://gcc.gnu.org/">GCC</a> from source on CentOS 7.</p>
<pre><code>$ cat /etc/centos-release
CentOS Linux release 7.9.2009 (Core)

$ uname -r
5.7.12-1.el7.elrepo.x86_64
</code></pre>
<h2 id="download-gcc-source">Download GCC <a href="https://gcc.gnu.org/pub/gcc/releases/">source</a></h2>
<pre><code>$ curl -LO https://gcc.gnu.org/pub/gcc/releases/gcc-12.2.0/gcc-12.2.0.tar.gz
</code></pre>
<p>Untar the source file:</p>
<pre><code>$ tar zxf gcc-12.2.0.tar.gz
</code></pre>
<h2 id="download-the-dependent-libraries">Download the dependent libraries</h2>
<pre><code>$ cd gcc-12.2.0/
$ ./contrib/download_prerequisites
2023-02-01 00:41:01 URL:http://gcc.gnu.org/pub/gcc/infrastructure/gmp-6.2.1.tar.bz2 [2493916/2493916] -&gt; &quot;gmp-6.2.1.tar.bz2&quot; [1]
2023-02-01 00:41:02 URL:http://gcc.gnu.org/pub/gcc/infrastructure/mpfr-4.1.0.tar.bz2 [1747243/1747243] -&gt; &quot;mpfr-4.1.0.tar.bz2&quot; [1]
2023-02-01 00:41:03 URL:http://gcc.gnu.org/pub/gcc/infrastructure/mpc-1.2.1.tar.gz [838731/838731] -&gt; &quot;mpc-1.2.1.tar.gz&quot; [1]
2023-02-01 00:41:04 URL:http://gcc.gnu.org/pub/gcc/infrastructure/isl-0.24.tar.bz2 [2261594/2261594] -&gt; &quot;isl-0.24.tar.bz2&quot; [1]
gmp-6.2.1.tar.bz2: OK
mpfr-4.1.0.tar.bz2: OK
mpc-1.2.1.tar.gz: OK
isl-0.24.tar.bz2: OK
All prerequisites downloaded successfully.
</code></pre>
<h2 id="configure-and-compile-the-source">Configure and compile the source</h2>
<pre><code>$ ./configure --enable-languages=c,c++ --disable-multilib
$ make -j$(nproc)
</code></pre>
<h2 id="install-gcc">Install GCC</h2>
<pre><code>$ make install
</code></pre>
<h2 id="verify-gcc-version">Verify GCC version</h2>
<pre><code>$ gcc --version
gcc (GCC) 12.2.0
</code></pre>
<h2 id="write-a-hello-world-c-program">Write a  &quot;hello world&quot; C program</h2>
<pre><code>$ vi hello.c
#include &lt;stdio.h&gt;
void main()
{
printf(&quot;Hello world!\n&quot;);
}
</code></pre>
<h2 id="compile-and-run-the-program">Compile and run the program</h2>
<pre><code>$ gcc -o hello hello.c
$ ./hello
Hello world!
</code></pre>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Surprised! How can the write IOPS be 10x faster than the cloud native disk performance]]></title><description><![CDATA[<p>In a competitive fio write performance benchmark between 3rd party storage solution and cloud native disk, we noticed that the write performance for the 3rd party storage solution is 10x faster than the cloud native. This usually seems impossible since we would argue that no one can beat the raw</p>]]></description><link>https://www.flamingbytes.com/blog/surprised-how-can-the-write-throughput-be-10x-faster-than-the-cloud-native-disk-performance/</link><guid isPermaLink="false">63d0cefe2eaec20e4c700378</guid><category><![CDATA[Benchmarking]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Wed, 25 Jan 2023 07:18:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1457969414820-5fdd86fc0b84?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fHJhY2V8ZW58MHx8fHwxNjc0NjMwNzE5&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1457969414820-5fdd86fc0b84?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fHJhY2V8ZW58MHx8fHwxNjc0NjMwNzE5&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Surprised! How can the write IOPS be 10x faster than the cloud native disk performance"><p>In a competitive fio write performance benchmark between 3rd party storage solution and cloud native disk, we noticed that the write performance for the 3rd party storage solution is 10x faster than the cloud native. This usually seems impossible since we would argue that no one can beat the raw disk performance. The following case shows an interesting write performance optimization from the storage solution under test.</p><!--kg-card-begin: markdown--><h2 id="cloud-native-raw-disk-performancefio4kwrite">Cloud native raw disk performance(fio,4k,write)</h2>
<p>From the benchmark result, it shows the IOPS limit of the cloud drive is ~7500. This aligns with the cloud storage SPEC in use.</p>
<p><img src="https://www.flamingbytes.com/content/images/posts/10xfast_1.jpg" alt="Surprised! How can the write IOPS be 10x faster than the cloud native disk performance" loading="lazy"><br>
<img src="https://www.flamingbytes.com/content/images/posts/10xfast_2.jpg" alt="Surprised! How can the write IOPS be 10x faster than the cloud native disk performance" loading="lazy"><br>
<img src="https://www.flamingbytes.com/content/images/posts/10xfast_3.jpg" alt="Surprised! How can the write IOPS be 10x faster than the cloud native disk performance" loading="lazy"></p>
<!--kg-card-end: markdown--><p></p><!--kg-card-begin: markdown--><h2 id="10x-faster-iops-is-observed">10x faster IOPS is observed!!!</h2>
<p>In the output of fio, the IOPS(&gt;75k) is 10x faster than the result from cloud native raw disk(~7500). This can be verified from the iostat output. The IOPS at logic volume layer is aligned with the fio output.</p>
<p><img src="https://www.flamingbytes.com/content/images/posts/10xfast_4.jpg" alt="Surprised! How can the write IOPS be 10x faster than the cloud native disk performance" loading="lazy"><br>
<img src="https://www.flamingbytes.com/content/images/posts/10xfast_5.jpg" alt="Surprised! How can the write IOPS be 10x faster than the cloud native disk performance" loading="lazy"><br>
<img src="https://www.flamingbytes.com/content/images/posts/10xfast_6.jpg" alt="Surprised! How can the write IOPS be 10x faster than the cloud native disk performance" loading="lazy"></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="iosize-matters">Iosize matters!!!</h2>
<p>When the write request comes to the physical disk from logic volume, the I/O size is changed from 4k to 400k. It indicates the smaller writes got merged to larger writes.</p>
<p><img src="https://www.flamingbytes.com/content/images/posts/10xfast_7.jpg" alt="Surprised! How can the write IOPS be 10x faster than the cloud native disk performance" loading="lazy"><br>
<img src="https://www.flamingbytes.com/content/images/posts/10xfast_8.jpg" alt="Surprised! How can the write IOPS be 10x faster than the cloud native disk performance" loading="lazy"><br>
<img src="https://www.flamingbytes.com/content/images/posts/10xfast_9.jpg" alt="Surprised! How can the write IOPS be 10x faster than the cloud native disk performance" loading="lazy"></p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="conclusion">Conclusion</h2>
<p>With limited IOPS on the cloud drive, larger IO size really help improve the write performance by reducing the write requests to disk. With proper write performance optimization at logic volume layer, the write performance can be boosted 10x faster with no surprise!!!</p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[fio direct I/O error with 1k blocksize]]></title><description><![CDATA[<p>When to run fio write with small blocksize(e.g. 1k), the following error is seen.</p><pre><code>$ fio --blocksize=1k --ioengine=libaio --readwrite=randwrite --filesize=2G --group_reporting --direct=1 --iodepth=128 --randrepeat=1 --end_fsync=1 --
name=job1 --numjobs=1 --filename=/mnt/fiomnt/fio.dat
job1: (g=0): rw=</code></pre>]]></description><link>https://www.flamingbytes.com/blog/fio-direct-i-o-error-with-1k-blocksize/</link><guid isPermaLink="false">63d0cadc2eaec20e4c700329</guid><category><![CDATA[Benchmarking]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Mon, 23 Jan 2023 06:39:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1566633806501-349d557a616d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDJ8fGFsaWdufGVufDB8fHx8MTY3NDYyODcwMw&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1566633806501-349d557a616d?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDJ8fGFsaWdufGVufDB8fHx8MTY3NDYyODcwMw&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="fio direct I/O error with 1k blocksize"><p>When to run fio write with small blocksize(e.g. 1k), the following error is seen.</p><pre><code>$ fio --blocksize=1k --ioengine=libaio --readwrite=randwrite --filesize=2G --group_reporting --direct=1 --iodepth=128 --randrepeat=1 --end_fsync=1 --
name=job1 --numjobs=1 --filename=/mnt/fiomnt/fio.dat
job1: (g=0): rw=randwrite, bs=(R) 1024B-1024B, (W) 1024B-1024B, (T) 1024B-1024B, ioengine=libaio, iodepth=128
fio-3.7
Starting 1 process
fio: io_u error on file /mnt/fiomnt/fio.dat: Invalid argument: write offset=129521664, buflen=1024
fio: io_u error on file /mnt/fiomnt/fio.dat: Invalid argument: write offset=1589760000, buflen=1024
fio: pid=93922, err=22/file:io_u.c:1747, func=io_u error, error=Invalid argument
job1: (groupid=0, jobs=1): err=22 (file:io_u.c:1747, func=io_u error, error=Invalid argument): pid=93922: Wed Jan 25 00:42:00 2023
cpu : usr=0.00%, sys=0.00%, ctx=1, majf=0, minf=14
IO depths : 1=0.8%, 2=1.6%, 4=3.1%, 8=6.2%, 16=12.5%, 32=25.0%, &amp;gt;=64=50.8%
submit : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.0%
complete : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, &amp;gt;=64=0.0%
issued rwts: total=0,128,0,0 short=0,0,0,0 dropped=0,0,0,0
latency : target=0, window=0, percentile=100.00%, depth=128</code></pre><p><strong>Cause:</strong></p><p>For direct I/O, &#xA0;the I/O size has to be multiple of filesystem/block device blocksize. In this case, the filesystem blocksize is 4k which can not be well aligned with the requested I/O size(1k). To fix this, the filesystem blocksize should be less than or equal to 1k.</p>]]></content:encoded></item><item><title><![CDATA[Tracking stock financial metrics in tradingview]]></title><description><![CDATA[In this post, we learn how to use tradingview.com to track financial metrics of the interested stock. It helps understand how the financial metrics support the stock price under the hood.]]></description><link>https://www.flamingbytes.com/blog/tracking-stock-financial-metrics-in-tradingview/</link><guid isPermaLink="false">63c5f75c7f98ed0ceabaa24f</guid><category><![CDATA[Investment]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Tue, 17 Jan 2023 05:35:07 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1560221328-12fe60f83ab8?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHN0b2NrfGVufDB8fHx8MTY3MzkxOTM4NA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<img src="https://images.unsplash.com/photo-1560221328-12fe60f83ab8?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fHN0b2NrfGVufDB8fHx8MTY3MzkxOTM4NA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Tracking stock financial metrics in tradingview"><p></p><p>In this post, we learn how to use tradingview.com to track financial metrics of the interested stock. It helps understand how the financial metrics support the stock price under the hood.</p><!--kg-card-begin: markdown--><h2 id="display-the-stock-price-in-year-view">Display the stock price in year view</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card"><img src="https://www.flamingbytes.com/content/images/2023/01/12m_price.png" class="kg-image" alt="Tracking stock financial metrics in tradingview" loading="lazy" width="1547" height="881" srcset="https://www.flamingbytes.com/content/images/size/w600/2023/01/12m_price.png 600w, https://www.flamingbytes.com/content/images/size/w1000/2023/01/12m_price.png 1000w, https://www.flamingbytes.com/content/images/2023/01/12m_price.png 1547w" sizes="(min-width: 720px) 720px"></figure><!--kg-card-begin: markdown--><h2 id="add-the-revenue-metric">Add the revenue metric</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card"><img src="https://www.flamingbytes.com/content/images/2023/01/revenue.png" class="kg-image" alt="Tracking stock financial metrics in tradingview" loading="lazy" width="1543" height="881" srcset="https://www.flamingbytes.com/content/images/size/w600/2023/01/revenue.png 600w, https://www.flamingbytes.com/content/images/size/w1000/2023/01/revenue.png 1000w, https://www.flamingbytes.com/content/images/2023/01/revenue.png 1543w" sizes="(min-width: 720px) 720px"></figure><!--kg-card-begin: markdown--><h2 id="add-the-operating-income-metric">Add the operating income metric</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card"><img src="https://www.flamingbytes.com/content/images/2023/01/operating_income.png" class="kg-image" alt="Tracking stock financial metrics in tradingview" loading="lazy" width="1544" height="880" srcset="https://www.flamingbytes.com/content/images/size/w600/2023/01/operating_income.png 600w, https://www.flamingbytes.com/content/images/size/w1000/2023/01/operating_income.png 1000w, https://www.flamingbytes.com/content/images/2023/01/operating_income.png 1544w" sizes="(min-width: 720px) 720px"></figure><!--kg-card-begin: markdown--><h2 id="add-the-current-ratio-metric">Add the current ratio metric</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card"><img src="https://www.flamingbytes.com/content/images/2023/01/quick_ratio.png" class="kg-image" alt="Tracking stock financial metrics in tradingview" loading="lazy" width="1543" height="877" srcset="https://www.flamingbytes.com/content/images/size/w600/2023/01/quick_ratio.png 600w, https://www.flamingbytes.com/content/images/size/w1000/2023/01/quick_ratio.png 1000w, https://www.flamingbytes.com/content/images/2023/01/quick_ratio.png 1543w" sizes="(min-width: 720px) 720px"></figure><!--kg-card-begin: markdown--><h2 id="add-the-pe-ratio">Add the P/E ratio</h2>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card"><img src="https://www.flamingbytes.com/content/images/2023/01/pe.png" class="kg-image" alt="Tracking stock financial metrics in tradingview" loading="lazy" width="1540" height="875" srcset="https://www.flamingbytes.com/content/images/size/w600/2023/01/pe.png 600w, https://www.flamingbytes.com/content/images/size/w1000/2023/01/pe.png 1000w, https://www.flamingbytes.com/content/images/2023/01/pe.png 1540w" sizes="(min-width: 720px) 720px"></figure><!--kg-card-begin: markdown--><h2 id="check-the-trend-for-the-added-metrics">Check the trend for the added metrics</h2>
<p>In the case of Tesla stock, the prive surged in 2020 and 2021. Notice that the revenue and operating income increased tremendously at the same time.</p>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card"><img src="https://www.flamingbytes.com/content/images/2023/01/indicators.png" class="kg-image" alt="Tracking stock financial metrics in tradingview" loading="lazy" width="1545" height="881" srcset="https://www.flamingbytes.com/content/images/size/w600/2023/01/indicators.png 600w, https://www.flamingbytes.com/content/images/size/w1000/2023/01/indicators.png 1000w, https://www.flamingbytes.com/content/images/2023/01/indicators.png 1545w" sizes="(min-width: 720px) 720px"></figure>]]></content:encoded></item><item><title><![CDATA[Using ANOVA in R to analyze US COVID data to understand age impact to death rate]]></title><description><![CDATA[A great example to use ANOVA in R to analyze complicated data.]]></description><link>https://www.flamingbytes.com/blog/using-anova-in-r-to-analyze-us-covid-data/</link><guid isPermaLink="false">63c4d8dafc850b0e49cce665</guid><category><![CDATA[Big Data]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Thu, 12 Jan 2023 04:57:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1583946099379-f9c9cb8bc030?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDIwfHxjb3ZpZCUyMDE5fGVufDB8fHx8MTY3Mzg0NTEyMA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><h2 id="goal">Goal</h2>
<img src="https://images.unsplash.com/photo-1583946099379-f9c9cb8bc030?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDIwfHxjb3ZpZCUyMDE5fGVufDB8fHx8MTY3Mzg0NTEyMA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Using ANOVA in R to analyze US COVID data to understand age impact to death rate"><p>We want to analysis the relationship between age and covid death rate in US.</p>
<h2 id="download-the-data">Download the data</h2>
<p>We will use NCHS(National Center for Health Statistics) as our data source.<br>
Visit <a href="https://data.cdc.gov/browse?category=NCHS&amp;sortBy=last_modified">https://data.cdc.gov/browse?category=NCHS&amp;sortBy=last_modified</a>, and search <code>VSRR Quarterly</code>, we will find the data we are intrest.</p>
<p><a href="https://data.cdc.gov/NCHS/NCHS-VSRR-Quarterly-provisional-estimates-for-sele/489q-934x">https://data.cdc.gov/NCHS/NCHS-VSRR-Quarterly-provisional-estimates-for-sele/489q-934x</a>, in this page, we can export data into csv file.</p>
<p>With that, we may can download data source csv, <code>NCHS_-_VSRR_Quarterly_provisional_estimates_for_selected_indicators_of_mortality.csv</code></p>
<h2 id="load-the-data">Load the data</h2>
<pre><code>library(&quot;dplyr&quot;)
library(&quot;ggplot2&quot;)
library(&quot;janitor&quot;)
library(&quot;tidyr&quot;)
library(&quot;readr&quot;)
library(&quot;sjPlot&quot;)
df &lt;- readr::read_csv(file.path(getwd(), &quot;NCHS_-_VSRR_Quarterly_provisional_estimates_for_selected_indicators_of_mortality.csv&quot;), col_names = TRUE)
df &lt;- clean_names(df)
# To fix the colname format from origin csv file
df &lt;- df %&gt;% rename(&quot;rate_age_65_74&quot; = &quot;rate_65_74&quot;)
</code></pre>
<h2 id="filter-and-select">Filter and Select</h2>
<pre><code>df1 &lt;- df %&gt;%
    filter(time_period == &quot;3-month period&quot; &amp; rate_type == &quot;Crude&quot; &amp; cause_of_death %in% c(&quot;COVID-19&quot;)) %&gt;%
    select(year_and_quarter, rate_age_1_4, rate_age_5_14,rate_age_15_24, rate_age_25_34,rate_age_35_44, rate_age_45_54,rate_age_55_64,rate_age_65_74,rate_age_75_84,rate_age_85_plus)
  # take a quick look from column&apos;s point of view
!&gt; glimpse(df1)
 Rows: 14
 Columns: 11
 $ year_and_quarter &lt;chr&gt; &quot;2019 Q1&quot;, &quot;2019 Q2&quot;, &quot;2019 Q3&quot;, &quot;2019 Q4&quot;, &quot;2020 Q1&quot;&#x2026;
 $ rate_age_1_4     &lt;dbl&gt; NA, NA, NA, NA, NA, 0.2, NA, 0.2, 0.2, 0.2, 0.6, 0.4,&#x2026;
 $ rate_age_5_14    &lt;dbl&gt; NA, NA, NA, NA, NA, 0.1, 0.2, 0.2, 0.2, 0.1, 0.6, 0.5&#x2026;
 $ rate_age_15_24   &lt;dbl&gt; NA, NA, NA, NA, 0.1, 1.4, 1.5, 1.6, 1.9, 1.0, 5.9, 4.&#x2026;
 $ rate_age_25_34   &lt;dbl&gt; NA, NA, NA, NA, 0.8, 6.6, 5.4, 6.7, 8.9, 4.6, 23.8, 1&#x2026;
 $ rate_age_35_44   &lt;dbl&gt; NA, NA, NA, NA, 2.1, 18.8, 16.1, 20.6, 25.1, 11.9, 65&#x2026;
 $ rate_age_45_54   &lt;dbl&gt; NA, NA, NA, NA, 4.9, 56.1, 42.8, 64.4, 79.9, 33.9, 14&#x2026;
 $ rate_age_55_64   &lt;dbl&gt; NA, NA, NA, NA, 9.3, 129.8, 96.0, 162.0, 201.9, 67.4,&#x2026;
 $ rate_age_65_74   &lt;dbl&gt; NA, NA, NA, NA, 19.0, 293.6, 206.7, 413.6, 464.8, 109&#x2026;
 $ rate_age_75_84   &lt;dbl&gt; NA, NA, NA, NA, 43.9, 725.6, 465.8, 1112.4, 1110.7, 1&#x2026;
 $ rate_age_85_plus &lt;dbl&gt; NA, NA, NA, NA, 97.7, 2210.8, 1127.2, 3101.9, 2783.8,&#x2026;
</code></pre>
<h2 id="pivotlonger-to-reorg-the-data-for-grouping"><code>pivot_longer</code> to reorg the data for grouping</h2>
<pre><code>df2 = df1 %&gt;% pivot_longer(names_to = &quot;rate_type&quot;, values_to = &quot;rate_of_10k&quot;,cols = -c(year_and_quarter))
# convert NA to 0
df2 &lt;- df2 %&gt;%
    mutate_at(c(&quot;rate_of_10k&quot;), ~coalesce(.,0))
!&gt; df2
 # A tibble: 140 &#xD7; 3
    year_and_quarter rate_type        rate_of_10k
    &lt;chr&gt;            &lt;chr&gt;                  &lt;dbl&gt;
  1 2019 Q1          rate_age_1_4               0
  2 2019 Q1          rate_age_5_14              0
  3 2019 Q1          rate_age_15_24             0
  4 2019 Q1          rate_age_25_34             0
  5 2019 Q1          rate_age_35_44             0
  6 2019 Q1          rate_age_45_54             0
  7 2019 Q1          rate_age_55_64             0
  8 2019 Q1          rate_age_65_74             0
  9 2019 Q1          rate_age_75_84             0
 10 2019 Q1          rate_age_85_plus           0	
</code></pre>
<h2 id="draw-diagram-for-each-group">Draw diagram for each group</h2>
<pre><code>plotdata &lt;- df2 %&gt;%
    group_by(rate_type) %&gt;%
    summarize(n = n(),
            mean = mean(rate_of_10k),
            sd = sd(rate_of_10k),
            ci = qt(0.975, df = n - 1) * sd / sqrt(n))
p = ggplot(plotdata,
       aes(x = factor(rate_type, level = c(&apos;rate_age_1_4&apos;,&apos;rate_age_5_14&apos;,&apos;rate_age_15_24&apos;,&apos;rate_age_25_34&apos;,&apos;rate_age_35_44&apos;,&apos;rate_age_45_54&apos;,&apos;rate_age_55_64&apos;,&apos;rate_age_65_74&apos;,&apos;rate_age_75_84&apos;,&apos;rate_age_85_plus&apos;))
         , y = mean, group = 1)) +
    geom_line(linetype=&quot;dashed&quot;, color=&quot;darkgrey&quot;) +
    geom_errorbar(aes(ymin = mean - ci,
                      ymax = mean + ci),
                  width = .2) +
    geom_point(size = 3, color=&quot;red&quot;) +
    scale_y_continuous(breaks=seq(0,1800,100)) +
    theme_bw() +
    labs(x=&quot;rate_type&quot;,
         y=&quot;rate_of_10k&quot;,
         title=&quot;Mean Plot with 95% Confidence Interval&quot;)
save_plot(&quot;covid_plot_age_impact1.svg&quot;, fig = p, width=30, height=20)
</code></pre>
<p><img src="https://www.flamingbytes.com/content/images/posts/covid_plot_age_impact1.svg" alt="Using ANOVA in R to analyze US COVID data to understand age impact to death rate" loading="lazy"></p>
<h2 id="anova-analysis">ANOVA analysis</h2>
<p>Analysis of variance (ANOVA) is a collection of statistical models and their associated estimation procedures (such as the &quot;variation&quot; among and between groups) used to analyze the differences among means.<br>
It&apos;s very useful in our case, <code>aov</code> from R make it very easy to use, see <a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/aov">https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/aov</a> for more detail.</p>
<pre><code>fit &lt;- aov(rate_of_10k ~ rate_type, data=df2)
summary(fit)
!&gt; summary(fit)
              Df   Sum Sq Mean Sq F value   Pr(&gt;F)
 rate_type     9 12988087 1443121   10.21 8.49e-12 ***
 Residuals   130 18370513  141312
 ---
 Signif. codes:  0 &#x2018;***&#x2019; 0.001 &#x2018;**&#x2019; 0.01 &#x2018;*&#x2019; 0.05 &#x2018;.&#x2019; 0.1 &#x2018; &#x2019; 1
</code></pre>
<p>we saw <code>8.49e-12 ***</code>, which means age has big impact on covid death rate.</p>
<h2 id="compare-diffrent-age-ranges">Compare diffrent age ranges</h2>
<pre><code>pairwise &lt;- TukeyHSD(fit)
pairwise

 + pairwise
 &gt;   Tukey multiple comparisons of means
     95% family-wise confidence level

 Fit: aov(formula = rate_of_10k ~ rate_type, data = df2)

 $rate_type
                                          diff        lwr       upr     p adj
 rate_age_15_24-rate_age_1_4        1.25000000 -456.16974  458.6697 1.0000000
 rate_age_25_34-rate_age_1_4        5.87857143 -451.54117  463.2983 1.0000000
 rate_age_35_44-rate_age_1_4       16.50714286 -440.91259  473.9269 1.0000000
 rate_age_45_54-rate_age_1_4       43.45714286 -413.96259  500.8769 0.9999996
 rate_age_5_14-rate_age_1_4        -0.02857143 -457.44831  457.3912 1.0000000
 ....
</code></pre>
<p>if <code>p adj</code> is close to 1, it means <code>no big difference</code> for this pair<br>
if <code>p adj</code> is close to 0, it means <code>big difference</code> for this pair</p>
<h2 id="draw-diagram-for-pairs-comparisons">Draw diagram for pairs comparisons</h2>
<pre><code>plotdata &lt;- as.data.frame(pairwise[[1]])
plotdata$conditions &lt;- row.names(plotdata)
p = ggplot(data=plotdata, aes(x=conditions, y=diff)) +
  geom_errorbar(aes(ymin=lwr, ymax=upr, width=.2)) +
  geom_hline(yintercept=0, color=&quot;red&quot;, linetype=&quot;dashed&quot;) +
  geom_point(size=3, color=&quot;red&quot;) +
  theme_bw() +
  labs(y=&quot;Difference in mean levels&quot;, x=&quot;&quot;,
       title=&quot;95% family-wise confidence level&quot;) +
   coord_flip()
save_plot(&quot;covid_plot_age_impact2.svg&quot;, fig = p, width=30, height=20)
</code></pre>
<p><img src="https://www.flamingbytes.com/content/images/posts/covid_plot_age_impact2.svg" alt="Using ANOVA in R to analyze US COVID data to understand age impact to death rate" loading="lazy"></p>
<h2 id="conclusion">Conclusion</h2>
<ul>
<li>Age does have big impact for covid death rate.</li>
<li>85+ was impacted the most.</li>
<li>For 35-,  the death rate is very low, and no big difference from age 0-35.</li>
</ul>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Using R to analyze US COVID pandemic waves and peaks]]></title><description><![CDATA[A great example to use R to analyze data.]]></description><link>https://www.flamingbytes.com/blog/using-r-to-analyze-us-covid-waves-and-peaks/</link><guid isPermaLink="false">63c2f4d2639c6f0d6ee203e3</guid><category><![CDATA[Big Data]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Wed, 11 Jan 2023 18:33:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1593007791459-4b05e1158229?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDh8fGNvdmlkfGVufDB8fHx8MTY3MzcyMTIyMw&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><h2 id="goal">Goal</h2>
<img src="https://images.unsplash.com/photo-1593007791459-4b05e1158229?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDh8fGNvdmlkfGVufDB8fHx8MTY3MzcyMTIyMw&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Using R to analyze US COVID pandemic waves and peaks"><p>According to weekly data between 2020 to 2022, we want to get to know the waves and peaks of COVID pandemic in these years.</p>
<h2 id="download-the-data">Download the data</h2>
<p>We will continue to use NCHS(National Center for Health Statistics) as our data source.<br>
Visit <a href="https://data.cdc.gov/browse?category=NCHS&amp;sortBy=last_modified">https://data.cdc.gov/browse?category=NCHS&amp;sortBy=last_modified</a>, and search <code>Provisional COVID-19 Death Counts by Week</code>, we will find the data we are intrest.</p>
<p><a href="https://data.cdc.gov/NCHS/Provisional-COVID-19-Death-Counts-by-Week-Ending-D/r8kw-7aab">https://data.cdc.gov/NCHS/Provisional-COVID-19-Death-Counts-by-Week-Ending-D/r8kw-7aab</a>, in this page, we can export data into csv file.</p>
<p>With that, we may get the data source csv, <code>Provisional_COVID-19_Death_Counts_by_Week_Ending_Date_and_State.csv</code>.</p>
<h2 id="load-the-data">Load the data</h2>
<pre><code>library(&quot;dplyr&quot;)
library(&quot;janitor&quot;)
library(&quot;tidyr&quot;)
library(&quot;readr&quot;)
df &lt;- readr::read_csv(file.path(getwd(), &quot;Provisional_COVID-19_Death_Counts_by_Week_Ending_Date_and_State.csv&quot;), col_names = TRUE)
df &lt;- clean_names(df)
tmp_start_date &lt;- strptime(df$start_date, &quot;%m/%d/%Y&quot;)
df$start_date &lt;- format(tmp_start_date, &quot;%Y-%m-%d&quot;)

 &gt; glimpse(df)
 Rows: 10,800
 Columns: 17
 $ data_as_of                             &lt;chr&gt; &quot;01/09/2023&quot;, &quot;01/09/2023&quot;, &quot;01&#x2026;
 $ start_date                             &lt;chr&gt; &quot;2019-12-29&quot;, &quot;2020-01-05&quot;, &quot;20&#x2026;
 $ end_date                               &lt;chr&gt; &quot;01/04/2020&quot;, &quot;01/11/2020&quot;, &quot;01&#x2026;
 $ group                                  &lt;chr&gt; &quot;By Week&quot;, &quot;By Week&quot;, &quot;By Week&quot;&#x2026;
 $ year                                   &lt;chr&gt; &quot;2019/2020&quot;, &quot;2020&quot;, &quot;2020&quot;, &quot;2&#x2026;
 $ month                                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA,&#x2026;
 $ mmwr_week                              &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, &#x2026;
 $ week_ending_date                       &lt;chr&gt; &quot;01/04/2020&quot;, &quot;01/11/2020&quot;, &quot;01&#x2026;
 $ state                                  &lt;chr&gt; &quot;United States&quot;, &quot;United States&#x2026;
 $ covid_19_deaths                        &lt;dbl&gt; 0, 1, 2, 3, 0, 4, 6, 6, 9, 38, &#x2026;
 $ total_deaths                           &lt;dbl&gt; 60176, 60734, 59362, 59162, 588&#x2026;
 $ percent_of_expected_deaths             &lt;dbl&gt; 98, 97, 98, 99, 99, 100, 100, 1&#x2026;
 $ pneumonia_deaths                       &lt;dbl&gt; 4111, 4153, 4066, 3915, 3818, 3&#x2026;
 $ pneumonia_and_covid_19_deaths          &lt;dbl&gt; 0, 1, 2, 0, 0, 1, 1, 3, 5, 19, &#x2026;
 $ influenza_deaths                       &lt;dbl&gt; 434, 475, 468, 500, 481, 520, 5&#x2026;
 $ pneumonia_influenza_or_covid_19_deaths &lt;dbl&gt; 4545, 4628, 4534, 4418, 4299, 4&#x2026;
 $ footnote                               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA,&#x2026;

 !&gt; df
 # A tibble: 10,800 &#xD7; 17
    data_as_of start_date end_d&#x2026;&#xB9; group year  month mmwr_&#x2026;&#xB2; week_&#x2026;&#xB3; state covid&#x2026;&#x2074;
    &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;
  1 01/09/2023 2019-12-29 01/04/&#x2026; By W&#x2026; 2019&#x2026;    NA       1 01/04/&#x2026; Unit&#x2026;       0
  2 01/09/2023 2020-01-05 01/11/&#x2026; By W&#x2026; 2020     NA       2 01/11/&#x2026; Unit&#x2026;       1
  3 01/09/2023 2020-01-12 01/18/&#x2026; By W&#x2026; 2020     NA       3 01/18/&#x2026; Unit&#x2026;       2
  4 01/09/2023 2020-01-19 01/25/&#x2026; By W&#x2026; 2020     NA       4 01/25/&#x2026; Unit&#x2026;       3
  5 01/09/2023 2020-01-26 02/01/&#x2026; By W&#x2026; 2020     NA       5 02/01/&#x2026; Unit&#x2026;       0
  6 01/09/2023 2020-02-02 02/08/&#x2026; By W&#x2026; 2020     NA       6 02/08/&#x2026; Unit&#x2026;       4
  7 01/09/2023 2020-02-09 02/15/&#x2026; By W&#x2026; 2020     NA       7 02/15/&#x2026; Unit&#x2026;       6
  8 01/09/2023 2020-02-16 02/22/&#x2026; By W&#x2026; 2020     NA       8 02/22/&#x2026; Unit&#x2026;       6
  9 01/09/2023 2020-02-23 02/29/&#x2026; By W&#x2026; 2020     NA       9 02/29/&#x2026; Unit&#x2026;       9
 10 01/09/2023 2020-03-01 03/07/&#x2026; By W&#x2026; 2020     NA      10 03/07/&#x2026; Unit&#x2026;      38
 # &#x2026; with 10,790 more rows, 7 more variables: total_deaths &lt;dbl&gt;,
 #   percent_of_expected_deaths &lt;dbl&gt;, pneumonia_deaths &lt;dbl&gt;,
 #   pneumonia_and_covid_19_deaths &lt;dbl&gt;, influenza_deaths &lt;dbl&gt;,
 #   pneumonia_influenza_or_covid_19_deaths &lt;dbl&gt;, footnote &lt;chr&gt;, and
 #   abbreviated variable names &#xB9; end_date, &#xB2; mmwr_week, &#xB3; week_ending_date,
 #   &#x2074; covid_19_deaths
 # &#x2139; Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names
</code></pre>
<h2 id="identify-the-data-we-want-to-focus">Identify the data we want to focus</h2>
<p>As we can see, there are 4 diffrent groups, and it has the <code>whole United states</code> and each state&apos;s data</p>
<pre><code>&gt; unique(df$group)
[1] &quot;By Week&quot;  &quot;By Month&quot; &quot;By Year&quot;  &quot;By Total&quot;
&gt;
</code></pre>
<p>We only want to get the weekly data, so we may want to <code>filter</code> with &quot;group=By Week&quot;, and &quot;state=United states&quot;<br>
in the mean time, we may only want to <code>select</code> only 2 columns.</p>
<ul>
<li>start_date</li>
<li>covid_19_deaths</li>
</ul>
<pre><code>&gt; df1 &lt;- df %&gt;%
    filter(state == &quot;United States&quot; &amp; group == &quot;By Week&quot;) %&gt;%
    select(start_date, covid_19_deaths)
&gt; print(df1,n=20)
+ &gt; # A tibble: 158 &#xD7; 2
   start_date covid_19_deaths
   &lt;chr&gt;                &lt;dbl&gt;
 1 2019-12-29               0
 2 2020-01-05               1
 3 2020-01-12               2
 4 2020-01-19               3
 5 2020-01-26               0
 6 2020-02-02               4
 7 2020-02-09               6
 8 2020-02-16               6
 9 2020-02-23               9
10 2020-03-01              38
11 2020-03-08              60
12 2020-03-15             588
13 2020-03-22            3226
14 2020-03-29           10141
15 2020-04-05           16347
16 2020-04-12           17221
17 2020-04-19           15557
18 2020-04-26           13223
19 2020-05-03           11243
20 2020-05-10            9239
...

</code></pre>
<h2 id="draw-the-graph-to-see-the-wave">Draw the graph to see the wave</h2>
<pre><code>library(&quot;ggplot2&quot;)
library(&quot;sjPlot&quot;)
p = ggplot(df1, aes( x=start_date, y=covid_19_deaths, group=1)) +
    geom_line(color=&quot;blue&quot;) +
    theme(axis.text.x=element_text(angle=45,hjust=1,size=5))
save_plot(&quot;covid_plot_weekly_wave.svg&quot;, fig = p, width=60, height=20)
</code></pre>
<p><img src="https://www.flamingbytes.com/content/images/posts/covid_plot_weekly_wave.svg" alt="Using R to analyze US COVID pandemic waves and peaks" loading="lazy"></p>
<h2 id="find-the-peak-by-r-mark-it-in-the-graph">Find the peak by R mark it in the graph</h2>
<p>From above graph, we can easily to figure out the waves and peaks, but we also can let R help us to do it, it&apos;s pretty useful if we have to deal with many data and many graphs.</p>
<p>To achive it, firstly we can call <code>findpeaks</code> from <code>pracma</code> library to find the peaks</p>
<pre><code>library(&quot;pracma&quot;)
+ peaks = findpeaks(df1$covid_19_deaths, npeaks=5,  sortstr=TRUE)
&gt; &gt; peaks
      [,1] [,2] [,3] [,4]
[1,] 26027   54   40   66
[2,] 21364  108   98  121
[3,] 17221   16    8   26
[4,] 15536   88   79   98
[5,]  8308   31   26   38
&gt;
</code></pre>
<p>The 2nd column means the the row index of the peak. in this case, we can tell, the 54th row has the top peak covid death number <code>26027</code>.</p>
<p>It&apos;s not very obvious which week(start_date) is hitting the peak, so we can do something like this.</p>
<pre><code>is_peak &lt;- vector( &quot;logical&quot; , length(df1$covid_19_deaths ))
df1$is_peak = is_peak

for (x in peaks[,2]) {
  df1$is_peak[x] = TRUE
}
</code></pre>
<p>As you can see, we added a new column <code>is_peak</code>, so we can use it to filter out those none peak data, sort the peak data points.</p>
<pre><code>!&gt; df2 = df1 %&gt;% filter(is_peak == TRUE)
 + df2[order(-df2$covid_19_deaths),]
 &gt; # A tibble: 5 &#xD7; 3
   start_date covid_19_deaths is_peak
   &lt;chr&gt;                &lt;dbl&gt; &lt;lgl&gt;
 1 2021-01-03           26027 TRUE
 2 2022-01-16           21364 TRUE
 3 2020-04-12           17221 TRUE
 4 2021-08-29           15536 TRUE
 5 2020-07-26            8308 TRUE
 &gt; &gt;
</code></pre>
<h2 id="hightlight-the-peak-points">Hightlight the peak points</h2>
<pre><code>p = ggplot(df1, aes(x=start_date, y=covid_19_deaths, group=1)) +
    geom_line(color=&quot;blue&quot;) +
    geom_point(data = . %&gt;% filter(is_peak == TRUE), stat=&quot;identity&quot;, size = 4, color = &quot;red&quot;) +
    scale_y_continuous(breaks=seq(0,30000,4000)) +
    theme(axis.text.x=element_text(angle=45,hjust=1,size=5))

save_plot(&quot;covid_plot_weekly_peak.svg&quot;, fig = p, width=60, height=20)
</code></pre>
<p><img src="https://www.flamingbytes.com/content/images/posts/covid_plot_weekly_peak.svg" alt="Using R to analyze US COVID pandemic waves and peaks" loading="lazy"></p>
<h2 id="other-finding">Other finding</h2>
<pre><code>!&gt; &gt; sum(df1$covid_19_deaths)
 [1] 1089714   ===&gt; the total covid_19_deaths death number from 2020 to 2022

!&gt; summary(df1$covid_19_deaths)
    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
       0    2223    4428    6897    9862   26027
 &gt;
!&gt; df3 &lt;- df %&gt;%
 +     filter(state == &quot;United States&quot; &amp; group == &quot;By Week&quot;) %&gt;%
 +     select(start_date, total_deaths)
 + sum(df3$total_deaths)
 + &gt; [1] 10077273  ===&gt; the total death number from 2020 to 2022 
 + summary(df3$total_deaths)
 &gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
    7100   58522   60451   63780   68610   87415
 &gt;
</code></pre>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Using R to analyze the quarterly US COVID data]]></title><description><![CDATA[An R example to analyze big amount of data]]></description><link>https://www.flamingbytes.com/blog/analysis-us-quartely-covid-data-from-cdc/</link><guid isPermaLink="false">63bced3f16d5d70e3a76d7f2</guid><category><![CDATA[Big Data]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Tue, 10 Jan 2023 05:02:33 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDE1fHxkYXRhJTIwbWluaW5nfGVufDB8fHx8MTY3MzMyNTgxNw&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><h2 id="goal">Goal</h2>
<img src="https://images.unsplash.com/photo-1454165804606-c3d57bc86b40?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDE1fHxkYXRhJTIwbWluaW5nfGVufDB8fHx8MTY3MzMyNTgxNw&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Using R to analyze the quarterly US COVID data"><p>Based on the overall death data and COVID realated death data since 2019, we want to study the impact trend of COVID to the overall pupulation death of US in these years.</p>
<h2 id="download-the-data">Download the data</h2>
<p>We will use NCHS(National Center for Health Statistics) as our data source.<br>
Visit <a href="https://data.cdc.gov/browse?category=NCHS&amp;sortBy=last_modified">https://data.cdc.gov/browse?category=NCHS&amp;sortBy=last_modified</a>, and search <code>VSRR Quarterly</code>, we will find the data we are intrested in.</p>
<p><a href="https://data.cdc.gov/NCHS/NCHS-VSRR-Quarterly-provisional-estimates-for-sele/489q-934x">https://data.cdc.gov/NCHS/NCHS-VSRR-Quarterly-provisional-estimates-for-sele/489q-934x</a></p>
<p>In this page, we can export data into csv file as <code>NCHS_-_VSRR_Quarterly_provisional_estimates_for_selected_indicators_of_mortality.csv</code></p>
<h2 id="take-a-quick-look-at-the-data">Take a quick look at the data</h2>
<p>To load the data:</p>
<pre><code># If &quot;readr&quot; not installed, run install.packages(&quot;readr&quot;) to install it
library(&quot;readr&quot;)
df &lt;- readr::read_csv(file.path(getwd(), &quot;NCHS_-_VSRR_Quarterly_provisional_estimates_for_selected_indicators_of_mortality.csv&quot;), col_names = TRUE)

</code></pre>
<p>To check the first few lines:</p>
<pre><code>&gt; head(df)
# A tibble: 6 &#xD7; 69
  Year a&#x2026;&#xB9; Time &#x2026;&#xB2; Cause&#x2026;&#xB3; Rate &#x2026;&#x2074; Unit  Overa&#x2026;&#x2075; Rate &#x2026;&#x2076; Rate &#x2026;&#x2077; Rate &#x2026;&#x2078; Rate &#x2026;&#x2079;
  &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
1 2019 Q1  12 mon&#x2026; All ca&#x2026; Age-ad&#x2026; Deat&#x2026;   712.    600.    844.       NA      NA
2 2019 Q1  12 mon&#x2026; Alzhei&#x2026; Age-ad&#x2026; Deat&#x2026;    29.6    33.1    23.8      NA      NA
3 2019 Q1  12 mon&#x2026; COVID-&#x2026; Age-ad&#x2026; Deat&#x2026;    NA      NA      NA        NA      NA
4 2019 Q1  12 mon&#x2026; Cancer  Age-ad&#x2026; Deat&#x2026;   148.    128.    175.       NA      NA
5 2019 Q1  12 mon&#x2026; Chroni&#x2026; Age-ad&#x2026; Deat&#x2026;    11       7.7    14.7      NA      NA
6 2019 Q1  12 mon&#x2026; Chroni&#x2026; Age-ad&#x2026; Deat&#x2026;    38.5    35.7    42.4      NA      NA
# &#x2026; with 59 more variables: `Rate Age 15-24` &lt;dbl&gt;, `Rate Age 25-34` &lt;dbl&gt;,
#   `Rate Age 35-44` &lt;dbl&gt;, `Rate Age 45-54` &lt;dbl&gt;, `Rate Age 55-64` &lt;dbl&gt;,
#   `Rate 65-74` &lt;dbl&gt;, `Rate Age 75-84` &lt;dbl&gt;, `Rate Age 85 plus` &lt;dbl&gt;,
#   `Rate Alaska` &lt;dbl&gt;, `Rate Alabama` &lt;dbl&gt;, `Rate Arkansas` &lt;dbl&gt;,
#   `Rate Arizona` &lt;dbl&gt;, `Rate California` &lt;dbl&gt;, `Rate Colorado` &lt;dbl&gt;,
#   `Rate Connecticut` &lt;dbl&gt;, `Rate District of Columbia` &lt;dbl&gt;,
#   `Rate Delaware` &lt;dbl&gt;, `Rate Florida` &lt;dbl&gt;, `Rate Georgia` &lt;dbl&gt;, &#x2026;
# &#x2139; Use `colnames()` to see all variable names

</code></pre>
<p>To get a summary:</p>
<pre><code>summary(df)
 Year and Quarter   Time Period        Cause of Death      Rate Type        
 Length:1232        Length:1232        Length:1232        Length:1232       
 Class :character   Class :character   Class :character   Class :character  
 Mode  :character   Mode  :character   Mode  :character   Mode  :character  

     Unit            Overall Rate     Rate Sex Female   Rate Sex Male    
 Length:1232        Min.   :   1.20   Min.   :   0.60   Min.   :   1.90  
 Class :character   1st Qu.:  11.40   1st Qu.:   6.95   1st Qu.:  13.20  
 Mode  :character   Median :  17.00   Median :  14.80   Median :  23.50  
                    Mean   :  80.51   Mean   :  70.56   Mean   :  91.63  
                    3rd Qu.:  50.60   3rd Qu.:  49.92   3rd Qu.:  65.42  
                    Max.   :1142.30   Max.   :1067.00   Max.   :1219.90  
                    NA&apos;s   :44        NA&apos;s   :44        NA&apos;s   :44       
  ...
</code></pre>
<p>To get glimpse from columns point of view:</p>
<pre><code>&gt; library(&quot;dplyr&quot;)
&gt; glimpse(df)
Rows: 1,232
Columns: 69
$ `Year and Quarter`          &lt;chr&gt; &quot;2019 Q1&quot;, &quot;2019 Q1&quot;, &quot;2019 Q1&quot;, &quot;2019 Q1&quot;&#x2026;
$ `Time Period`               &lt;chr&gt; &quot;12 months ending with quarter&quot;, &quot;12 month&#x2026;
$ `Cause of Death`            &lt;chr&gt; &quot;All causes&quot;, &quot;Alzheimer disease&quot;, &quot;COVID-&#x2026;
$ `Rate Type`                 &lt;chr&gt; &quot;Age-adjusted&quot;, &quot;Age-adjusted&quot;, &quot;Age-adjus&#x2026;
$ Unit                        &lt;chr&gt; &quot;Deaths per 100,000&quot;, &quot;Deaths per 100,000&quot;&#x2026;
$ `Overall Rate`              &lt;dbl&gt; 712.2, 29.6, NA, 148.1, 11.0, 38.5, 21.3, &#x2026;
$ `Rate Sex Female`           &lt;dbl&gt; 600.3, 33.1, NA, 127.9, 7.7, 35.7, 16.8, 1&#x2026;
$ `Rate Sex Male`             &lt;dbl&gt; 843.7, 23.8, NA, 175.4, 14.7, 42.4, 26.9, &#x2026;
$ `Rate Age 1-4`              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA&#x2026;
$ `Rate Age 5-14`             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA&#x2026;
$ `Rate Age 15-24`            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA&#x2026;
$ `Rate Age 25-34`            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA&#x2026;
$ `Rate Age 35-44`            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA&#x2026;
$ `Rate Age 45-54`            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA&#x2026;
$ `Rate Age 55-64`            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA&#x2026;
$ `Rate 65-74`                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA&#x2026;
$ `Rate Age 75-84`            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA&#x2026;
...
</code></pre>
<h2 id="clear-the-columns-name">Clear the columns name</h2>
<p>As we can see, the column names has space, it may cause some trouble while refering it in R, it&apos;s a common sugestion to convert space to &quot;_&quot; before doing any R o/p.</p>
<p>A good thing is , there is a R package can help us on it.</p>
<pre><code>&gt; library(&quot;janitor&quot;)
&gt; df &lt;- clean_names(df)
!&gt; glimpse(df)
 Rows: 1,232
 Columns: 69
 $ year_and_quarter          &lt;chr&gt; &quot;2019 Q1&quot;, &quot;2019 Q1&quot;, &quot;2019 Q1&quot;, &quot;2019 Q1&quot;, &#x2026;
 $ time_period               &lt;chr&gt; &quot;12 months ending with quarter&quot;, &quot;12 months &#x2026;
 $ cause_of_death            &lt;chr&gt; &quot;All causes&quot;, &quot;Alzheimer disease&quot;, &quot;COVID-19&#x2026;
 $ rate_type                 &lt;chr&gt; &quot;Age-adjusted&quot;, &quot;Age-adjusted&quot;, &quot;Age-adjuste&#x2026;
 $ unit                      &lt;chr&gt; &quot;Deaths per 100,000&quot;, &quot;Deaths per 100,000&quot;, &#x2026;
 $ overall_rate              &lt;dbl&gt; 712.2, 29.6, NA, 148.1, 11.0, 38.5, 21.3, 20&#x2026;
 $ rate_sex_female           &lt;dbl&gt; 600.3, 33.1, NA, 127.9, 7.7, 35.7, 16.8, 13.&#x2026;
 $ rate_sex_male             &lt;dbl&gt; 843.7, 23.8, NA, 175.4, 14.7, 42.4, 26.9, 27&#x2026;
 $ rate_age_1_4              &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, &#x2026;
</code></pre>
<p>As you can see, while we run <code>glimpse(df)</code>, the colum name has been changed from &quot;Year and Quarter&quot; to &quot;year_and_quarter&quot;.</p>
<h2 id="filter-and-select">Filter and select</h2>
<p>The raw data has so many columns and rows, but we just want to focus on those cols/rows we really have intrest.</p>
<p>We can use <code>filter</code>(applying on rows) and <code>select</code>(applying on columns) in such condition.</p>
<pre><code>&gt; df1 &lt;- df %&gt;%
      filter(time_period == &quot;3-month period&quot; &amp; rate_type == &quot;Crude&quot; &amp; cause_of_death %in% c(&quot;All causes&quot;, &quot;COVID-19&quot;)) %&gt;%
      select(year_and_quarter, cause_of_death, overall_rate)
&gt; print(df1,n=50)
 # A tibble: 28 &#xD7; 3
    year_and_quarter cause_of_death overall_rate
    &lt;chr&gt;            &lt;chr&gt;                 &lt;dbl&gt;
  1 2019 Q1          All causes            910
  2 2019 Q1          COVID-19               NA
  3 2019 Q2          All causes            851.
  4 2019 Q2          COVID-19               NA
  5 2019 Q3          All causes            827.
  6 2019 Q3          COVID-19               NA
  7 2019 Q4          All causes            891.
  8 2019 Q4          COVID-19               NA
  9 2020 Q1          All causes            945.
 10 2020 Q1          COVID-19                8.2
 11 2020 Q2          All causes           1035.
 12 2020 Q2          COVID-19              137.
 13 2020 Q3          All causes            985.
 14 2020 Q3          COVID-19               87.3
 15 2020 Q4          All causes           1142.
 16 2020 Q4          COVID-19              193.
 17 2021 Q1          All causes           1116
 18 2021 Q1          COVID-19              191.
 19 2021 Q2          All causes            915.
 20 2021 Q2          COVID-19               42.4
 21 2021 Q3          All causes           1051.
 22 2021 Q3          COVID-19              138.
 23 2021 Q4          All causes           1092.
 24 2021 Q4          COVID-19              131.
 25 2022 Q1          All causes           1116
 26 2022 Q1          COVID-19              150.
 27 2022 Q2          All causes            899.
 28 2022 Q2          COVID-19               17.6
</code></pre>
<p><code>%&gt;%</code> looks strange, it&apos;s just like <code>| (pipe)</code> in linux shell command.</p>
<pre><code>df1 &lt;- df %&gt;%
    filter(time_period == &quot;3-month period&quot; &amp; rate_type == &quot;Crude&quot; &amp; cause_of_death %in% c(&quot;All causes&quot;, &quot;COVID-19&quot;)) %&gt;%
    select(year_and_quarter, cause_of_death, overall_rate)
</code></pre>
<p>It means only keep those rows which meet those condition of <code>filter</code>, and those columns which meet condition of <code>select</code>.</p>
<h2 id="deal-with-na-value">Deal with NA value</h2>
<p>As you can see, in &quot;overall_rate&quot; column, there are few &quot;NA&quot; values, in this context it means 0, so we may want to convert it as 0 for future&apos;s process.</p>
<p>We can do it like as below.</p>
<pre><code> &gt; df1 &lt;- df1 %&gt;%
     mutate_at(c(&quot;overall_rate&quot;), ~coalesce(.,0))
</code></pre>
<p>It means , we want to convert all NA to 0 in &quot;overall_rate&quot; column.<br>
Now, let&apos;s check the df1 again, we can see all NA has been changed to 0.</p>
<pre><code>!+ &gt; df1
 # A tibble: 28 &#xD7; 3
    year_and_quarter cause_of_death overall_rate
    &lt;chr&gt;            &lt;chr&gt;                 &lt;dbl&gt;
  1 2019 Q1          All causes            910
  2 2019 Q1          COVID-19                0
  3 2019 Q2          All causes            851.
  4 2019 Q2          COVID-19                0
  5 2019 Q3          All causes            827.
  6 2019 Q3          COVID-19                0
  7 2019 Q4          All causes            891.
  8 2019 Q4          COVID-19                0
  9 2020 Q1          All causes            945.
 10 2020 Q1          COVID-19                8.2
 # &#x2026; with 18 more rows
</code></pre>
<h2 id="draw-diagram-for-the-whole-us-data">Draw diagram for the whole US data</h2>
<p>To draw a diagram directly:</p>
<pre><code>&gt; ggplot(df1, aes(fill=cause_of_death, x=year_and_quarter, y=overall_rate)) +
    geom_bar(position=&quot;stack&quot;, stat=&quot;identity&quot;) +
    geom_col() +
    geom_smooth(aes(group=cause_of_death)) +
    scale_y_continuous(breaks=seq(0,1500,100))
    theme_bw()
</code></pre>
<p>To save the diagram in a file:</p>
<pre><code>library(sjPlot)
p = ggplot(df1, aes(fill=cause_of_death, x=year_and_quarter, y=overall_rate)) +
    geom_bar(position=&quot;stack&quot;, stat=&quot;identity&quot;) +
    geom_col() +
    geom_smooth(aes(group=cause_of_death)) +
    scale_y_continuous(breaks=seq(0,1500,100)) +
    theme_bw()

save_plot(&quot;covid_plot.svg&quot;, fig = p, width=30, height=20)
</code></pre>
<p>The diagram looks like below.</p>
<!--kg-card-end: markdown--><figure class="kg-card kg-image-card"><img src="https://www.flamingbytes.com/content/images/2023/01/image-1.png" class="kg-image" alt="Using R to analyze the quarterly US COVID data" loading="lazy" width="1133" height="755" srcset="https://www.flamingbytes.com/content/images/size/w600/2023/01/image-1.png 600w, https://www.flamingbytes.com/content/images/size/w1000/2023/01/image-1.png 1000w, https://www.flamingbytes.com/content/images/2023/01/image-1.png 1133w" sizes="(min-width: 720px) 720px"></figure><!--kg-card-begin: markdown--><h2 id="draw-diagram-for-california-data">Draw diagram for California data</h2>
<p>Do you want to try it by yourself?</p>
<h2 id="createcalculate-a-new-column-for-covid-ratio">Create/Calculate a new column for covid ratio</h2>
<p>Somehow, we want to get to know the trend for covid ratio.</p>
<ul>
<li>covid_ratio = overall_rate_of_covid / overall_rate_of_all_causes</li>
</ul>
<pre><code>covid_death_rate &lt;- df1 %&gt;%
    filter(cause_of_death == &quot;COVID-19&quot;) %&gt;%
    select(&quot;overall_rate&quot;)

all_causes_rate &lt;- df1 %&gt;%
    filter(cause_of_death == &quot;All causes&quot;) %&gt;%
    select(overall_rate)

covid_ratio &lt;- covid_death_rate / all_causes_rate

df_ratio &lt;- df1 %&gt;%
    filter(cause_of_death == &quot;All causes&quot;) %&gt;%
    select(year_and_quarter)
df_ratio[&quot;covid_ratio&quot;] = covid_ratio


&gt; print(df_ratio)
# A tibble: 14 &#xD7; 2
   year_and_quarter covid_ratio
   &lt;chr&gt;                  &lt;dbl&gt;
 1 2019 Q1              0      
 2 2019 Q2              0      
 3 2019 Q3              0      
 4 2019 Q4              0      
 5 2020 Q1              0.00868
 6 2020 Q2              0.132  
 7 2020 Q3              0.0886 
 8 2020 Q4              0.169  
 9 2021 Q1              0.171  
10 2021 Q2              0.0463 
11 2021 Q3              0.131  
12 2021 Q4              0.120  
13 2022 Q1              0.134  
14 2022 Q2              0.0196 
</code></pre>
<h2 id="draw-diagram-for-covid-ratio">Draw diagram for covid ratio</h2>
<p>Do you want to try it by yourself?</p>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Getting started with R]]></title><description><![CDATA[A getting started guide to install and use  R.]]></description><link>https://www.flamingbytes.com/blog/getting-started-with-r/</link><guid isPermaLink="false">63bcea3316d5d70e3a76d7c5</guid><category><![CDATA[Big Data]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Sun, 08 Jan 2023 04:42:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1640158615573-cd28feb1bf4e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDl8fGRhdGElMjBtaW58ZW58MHx8fHwxNjczMzI1ODE2&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><h2 id="installation">Installation</h2>
<img src="https://images.unsplash.com/photo-1640158615573-cd28feb1bf4e?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDl8fGRhdGElMjBtaW58ZW58MHx8fHwxNjczMzI1ODE2&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Getting started with R"><p>The simplest way is to use Homebrew:</p>
<pre><code>$ brew install r
</code></pre>
<p>Another way is to download installation package from <a href="https://cloud.r-project.org/">https://cloud.r-project.org/</a></p>
<h2 id="hello-world-of-r">&quot;Hello world&quot; of R</h2>
<h3 id="run-it-from-r-console">Run it from R console</h3>
<p>Command <code>R</code> will start a R console, and you can run R code inside R console.</p>
<pre><code>(base) &#x279C;  benchling git:(b_test_pr) &#x2717; R

R version 4.2.2 (2022-10-31) -- &quot;Innocent and Trusting&quot;
Copyright (C) 2022 The R Foundation for Statistical Computing
Platform: aarch64-apple-darwin20 (64-bit)

...
&gt; print(&quot;hello,world&quot;)
[1] &quot;hello,world&quot;
</code></pre>
<h3 id="run-it-from-terminal">Run it from terminal</h3>
<p><code>Rscript</code> is a binary front-end to R, for use in scripting applications, see <a href="https://linux.die.net/man/1/rscript">https://linux.die.net/man/1/rscript</a> for more detail.</p>
<pre><code>(base) &#x279C;  R git:(b_test_pr) &#x2717; cat hello.R
print(&quot;hello,world&quot;)
(base) &#x279C;  R git:(b_test_pr) &#x2717; Rscript hello.R
[1] &quot;hello,world&quot;
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8578408127828851" crossorigin="anonymous"></script>
<ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-8578408127828851" data-ad-slot="5596270594"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script><!--kg-card-end: html--><!--kg-card-begin: markdown--><h2 id="install-commonly-used-packages">Install commonly used packages</h2>
<p>R installation package comes along with a lot of useful packages, besides that, there are a lot of useful packages available from <a href="https://cran.r-project.org/web/packages/">CRAN</a>.</p>
<p>Here are top 10 most important packages in R for data science.</p>
<ul>
<li>ggplot2</li>
<li>data.table</li>
<li>dplyr</li>
<li>tidyr</li>
<li>Shiny</li>
<li>plotly</li>
<li>knitr</li>
<li>mlr3</li>
</ul>
<p>To install those packages from CRAN, we can just simiply follow below steps.</p>
<ul>
<li>Start R console</li>
<li>Call &quot;install.packages(XXX)&quot;</li>
</ul>
<p>Here is an example:</p>
<pre><code>&gt; install.packages(&quot;mlr3&quot;)
--- Please select a CRAN mirror for use in this session ---
Secure CRAN mirrors

 1: 0-Cloud [https]
 2: Australia (Canberra) [https]
 3: Australia (Melbourne 1) [https]
 ....
 Selection: 1
also installing the dependencies &#x2018;globals&#x2019;, &#x2018;listenv&#x2019;, &#x2018;PRROC&#x2019;, &#x2018;future&#x2019;, &#x2018;future.apply&#x2019;, &#x2018;lgr&#x2019;, &#x2018;mlbench&#x2019;, &#x2018;mlr3measures&#x2019;, &#x2018;mlr3misc&#x2019;, &#x2018;parallelly&#x2019;, &#x2018;palmerpenguins&#x2019;, &#x2018;paradox&#x2019;

trying URL &apos;https://cloud.r-project.org/bin/macosx/big-sur-arm64/contrib/4.2/globals_0.16.2.tgz&apos;
...
&gt;&gt; library(mlr3)
&gt; ?mlr3
</code></pre>
<p>As above, after installation completes, we can try to run <code>library(&lt;package name&gt;)</code> to verify, and run <code>?&lt;package name&gt;</code> to see its document.</p>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://www.w3schools.com/r/r_get_started.asp">https://www.w3schools.com/r/r_get_started.asp</a></li>
<li><a href="https://www.datacamp.com/tutorial/top-ten-most-important-packages-in-r-for-data-science">https://www.datacamp.com/tutorial/top-ten-most-important-packages-in-r-for-data-science</a></li>
</ul>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[How to redirect the default "404 page not found" error page in Ghost blog]]></title><description><![CDATA[A method to redirect a non-existent page in Ghost blog. ]]></description><link>https://www.flamingbytes.com/blog/how-to-redirect-the-default-404-page-not-found-error-page-in-ghost-blog/</link><guid isPermaLink="false">63c335e0acbe8dfd252da58a</guid><category><![CDATA[Blog]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Thu, 05 Jan 2023 23:23:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1499750310107-5fef28a66643?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fGJsb2d8ZW58MHx8fHwxNjczNzM4NjE1&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="https://images.unsplash.com/photo-1499750310107-5fef28a66643?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fGJsb2d8ZW58MHx8fHwxNjczNzM4NjE1&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="How to redirect the default &quot;404 page not found&quot; error page in Ghost blog"><p>When users access a non-existent page, they may see a page which shows the message &quot;404 page not found&quot; in Ghost blog.</p>
<p>We can redirect the page to another page by creating a <strong>error-404.hbs</strong> file under the theme folder.</p>
<p>In the following example, we redirect the users to the website home page when they access a non-existent page.</p>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta http-equiv=&quot;refresh&quot; content=&quot;0; url=&apos;https://www.flamingbytes.com/&apos;&quot; /&gt;
  &lt;/head&gt;
  &lt;body&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[How to install GUI desktop on CentOS 7]]></title><description><![CDATA[Install GNOME desktop via the groups option of yum.]]></description><link>https://www.flamingbytes.com/blog/how-to-install-gui-desktop-on-centos-7/</link><guid isPermaLink="false">63c2f5b9639c6f0d6ee203fa</guid><category><![CDATA[Linux]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Wed, 04 Jan 2023 18:35:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1508739773434-c26b3d09e071?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fGRlc2t0b3B8ZW58MHx8fHwxNjczNzIxNDg0&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><img src="https://images.unsplash.com/photo-1508739773434-c26b3d09e071?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fGRlc2t0b3B8ZW58MHx8fHwxNjczNzIxNDg0&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="How to install GUI desktop on CentOS 7"><p>Install GNOME desktop via the groups option of yum:</p>
<pre><code>$ yum update
$ yum -y groups install &quot;GNOME Desktop&quot;
</code></pre>
<p>Inform the startx command which desktop env to run:</p>
<pre><code>$ echo &quot;exec gnome-session&quot; &gt;&gt; ~/.xinitrc
</code></pre>
<p>Manually start the GUI desktop:</p>
<pre><code>$ startx
</code></pre>
<p>Automaticlly start the GUI desktop after reboot:</p>
<pre><code>$ systemctl set-default graphical.target
$ reboot
</code></pre>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Using signals with kill command in Linux]]></title><description><![CDATA[Introduce how to use signals in Linux shell script with an example for sending SIGINT signal.]]></description><link>https://www.flamingbytes.com/blog/using-signals-with-kill-in-linux/</link><guid isPermaLink="false">63c37c5215cd8c0d7b6ee906</guid><category><![CDATA[Linux]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Wed, 04 Jan 2023 04:15:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1530635481267-00edc014d006?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDY3fHxzaWduYWx8ZW58MHx8fHwxNjczNzU2MTMy&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: markdown--><h2 id="usage-of-signals-with-kill">Usage of signals with kill</h2>
<pre><code>$ kill -l
 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP
 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1
11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM
16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP
21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ
26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR
31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3
38) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+8
43) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13
48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12
53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7
58) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-2
63) SIGRTMAX-1 64) SIGRTMAX
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="an-example-to-send-sigint-signal-in-shell">An example to send SIGINT signal in shell</h2>
<img src="https://images.unsplash.com/photo-1530635481267-00edc014d006?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDY3fHxzaWduYWx8ZW58MHx8fHwxNjczNzU2MTMy&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Using signals with kill command in Linux"><p>In the following example, we start strace for a given process for given amounts of seconds. Once the time is up, we send SIGINT(Ctrl+C) signal to stop the tracing process. And a trace report will be generated to the output file strace.c.out.</p>
<pre><code>$ cat strace_summary.sh
processname=$1
duration=$2
while true
do
    strace -p `pidof $processname` -c &gt; strace.c.out 2&gt;&amp;1 &amp;
    sleep $duration
    break
done

kill -2 `pidof strace`
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="reference">Reference</h2>
<ul>
<li><a href="https://linux.die.net/Bash-Beginners-Guide/sect_12_01.html#:~:text=The%20interrupt%20signal%2C%20sends%20SIGINT,job%20running%20in%20the%20foreground.&amp;text=The%20delayed%20suspend%20character.,background%20or%20kill%20the%20process.">Signals in Linux</a></li>
</ul>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Using virtctl to access virtual machine in Kubernetes]]></title><description><![CDATA[Using virtctl to control virtual machine related operations on your kubernetes cluster.]]></description><link>https://www.flamingbytes.com/blog/using-virtctl-to-access-virtual-machine-in-kubernetes/</link><guid isPermaLink="false">63b4b4a91527a00d97449fdf</guid><category><![CDATA[Big Data]]></category><dc:creator><![CDATA[relentlesstorm]]></dc:creator><pubDate>Mon, 02 Jan 2023 00:00:00 GMT</pubDate><media:content url="https://images.unsplash.com/photo-1667372335936-3dc4ff716017?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDEwfHxrdWJlcm5ldGVzfGVufDB8fHx8MTY3Mjc3NzAxNg&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" medium="image"/><content:encoded><![CDATA[<!--kg-card-begin: html--><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-8578408127828851" crossorigin="anonymous">
</script>
<ins class="adsbygoogle" style="display:block; text-align:center;" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-8578408127828851" data-ad-slot="5596270594">
</ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script><!--kg-card-end: html--><!--kg-card-begin: markdown--><h2 id="install-the-virtctl-client-tool">Install the virtctl client tool</h2>
<img src="https://images.unsplash.com/photo-1667372335936-3dc4ff716017?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MnwxMTc3M3wwfDF8c2VhcmNofDEwfHxrdWJlcm5ldGVzfGVufDB8fHx8MTY3Mjc3NzAxNg&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Using virtctl to access virtual machine in Kubernetes"><p>Basic VirtualMachineInstance operations can be performed with the stock kubectl utility. However, the virtctl binary utility is required to use advanced features such as:</p>
<ul>
<li>Serial and graphical console access</li>
</ul>
<p>It also provides convenience commands for:</p>
<ul>
<li>Starting and stopping VirtualMachineInstances</li>
<li>Live migrating VirtualMachineInstances</li>
<li>Uploading virtual machine disk images</li>
</ul>
<p>There are two ways to get it:</p>
<ul>
<li>the most recent version of the tool can be retrieved from the official release page</li>
<li>it can be installed as a kubectl plugin using krew</li>
</ul>
<p>Example:</p>
<pre><code class="language-shell">$ export VERSION=v0.48.1
$ wget https://github.com/kubevirt/kubevirt/releases/download/${VERSION}/virtctl-${VERSION}-linux-amd64
$ ln -s virtctl-v0.48.1-linux-amd64 virtctl
$ chmod +x virtctl-v0.48.1-linux-amd64
$ ./virtctl version
Client Version: version.Info{GitVersion:&quot;v0.48.1&quot;, ...}
</code></pre>
<h2 id="access-the-virtual-machine-console">Access the virtual machine console</h2>
<pre><code class="language-shell">$ ./virtctl -h
virtctl controls virtual machine related operations on your kubernetes cluster.

Available Commands:
  addvolume         add a volume to a running VM
  console           Connect to a console of a virtual machine instance.
  expose            Expose a virtual machine instance, virtual machine, or virtual machine instance replica set as a new service.
  fslist            Return full list of filesystems available on the guest machine.
  guestfs           Start a shell into the libguestfs pod
  guestosinfo       Return guest agent info about operating system.
  help              Help about any command
  image-upload      Upload a VM image to a DataVolume/PersistentVolumeClaim.
  migrate           Migrate a virtual machine.
  pause             Pause a virtual machine
  permitted-devices List the permitted devices for vmis.
  port-forward      Forward local ports to a virtualmachine or virtualmachineinstance.
  removevolume      remove a volume from a running VM
  restart           Restart a virtual machine.
  soft-reboot       Soft reboot a virtual machine instance
  ssh               Open a SSH connection to a virtual machine instance.
  start             Start a virtual machine.
  stop              Stop a virtual machine.
  unpause           Unpause a virtual machine
  usbredir          Redirect a usb device to a virtual machine instance.
  userlist          Return full list of logged in users on the guest machine.
  version           Print the client and server version information.
  vnc               Open a vnc connection to a virtual machine instance.

Use &quot;virtctl &lt;command&gt; --help&quot; for more information about a given command.
Use &quot;virtctl options&quot; for a list of global command-line options (applies to all commands).

$ ./virtctl console vm1
[root@vm1 output]# hostname
vm1
</code></pre>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://github.com/kubevirt/kubevirt/releases">https://github.com/kubevirt/kubevirt/releases</a></li>
<li><a href="https://kubevirt.io/user-guide/operations/virtctl_client_tool/">https://kubevirt.io/user-guide/operations/virtctl_client_tool/</a></li>
</ul>
<!--kg-card-end: markdown-->]]></content:encoded></item></channel></rss>