<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>OpenZFS - A pooled storage file system</title>
    <link rel="stylesheet" href="/assets/built/screen.css?v=6e3eba6684">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.12.3/tocbot.css">
    
    <style>
    .gh-content {
        position: relative;
    }

    .gh-toc > .toc-list {
        position: relative;
    }

    .toc-list {
        overflow: hidden;
        list-style: none;
    }

    @media (min-width: 1300px) {
        .gh-sidebar {
            position: absolute; 
            top: 0;
            bottom: 0;
            margin-top: 4vmin;
            margin-left: 2vmin;
            /*grid-column: wide-start / main-start; *//* Place the TOC to the left of the content */
            grid-column: wide-end / main-end; /* Place the TOC to the right of the content */
        }
    
        .gh-toc {
            position: sticky; /* On larger screens, TOC will stay in the same spot on the page */
            top: 4vmin;
        }
    }

    .gh-toc .is-active-link::before {
        background-color: var(--ghost-accent-color); /* Defines TOC accent color based on Accent color set in Ghost Admin */
    } 
    </style>

    <link rel="icon" href="https://relentlesstorm.github.io/content/images/size/w256h256/2023/01/FlamingBytes-logos_transparent-9.png" type="image/png" />
    <link rel="canonical" href="https://relentlesstorm.github.io/openzfs-a-pooled-storage-file-system/" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    
    <meta property="og:site_name" content="Flamingbytes" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="OpenZFS - A pooled storage file system" />
    <meta property="og:description" content="OpenZFS


The OpenZFS project is an open source derivative of the Oracle ZFS project. OpenZFS is an outstanding storage platform that encompasses the functionality of traditional filesystems, volume managers, and more, with consistent reliability, functionality and performance across all distributions.


Source1

Source2



ZFS and ZFS Pooled Storage


The ZFS file" />
    <meta property="og:url" content="https://relentlesstorm.github.io/openzfs-a-pooled-storage-file-system/" />
    <meta property="og:image" content="https://images.unsplash.com/photo-1461360228754-6e81c478b882?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDF8fGZpbGUlMjBzeXN0ZW18ZW58MHx8fHwxNjcyNzgyMTAz&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000" />
    <meta property="article:published_time" content="2022-03-16T00:00:00.000Z" />
    <meta property="article:modified_time" content="2023-01-03T21:42:23.000Z" />
    <meta property="article:tag" content="Cloud Storage" />
    
    <meta property="article:publisher" content="https://www.facebook.com/ghost" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="OpenZFS - A pooled storage file system" />
    <meta name="twitter:description" content="OpenZFS


The OpenZFS project is an open source derivative of the Oracle ZFS project. OpenZFS is an outstanding storage platform that encompasses the functionality of traditional filesystems, volume managers, and more, with consistent reliability, functionality and performance across all distributions.


Source1

Source2



ZFS and ZFS Pooled Storage


The ZFS file" />
    <meta name="twitter:url" content="https://relentlesstorm.github.io/openzfs-a-pooled-storage-file-system/" />
    <meta name="twitter:image" content="https://images.unsplash.com/photo-1461360228754-6e81c478b882?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDF8fGZpbGUlMjBzeXN0ZW18ZW58MHx8fHwxNjcyNzgyMTAz&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="relentlesstorm" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Cloud Storage" />
    <meta name="twitter:site" content="@ghost" />
    <meta property="og:image:width" content="2000" />
    <meta property="og:image:height" content="1328" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Flamingbytes",
        "url": "https://relentlesstorm.github.io/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://relentlesstorm.github.io/content/images/size/w256h256/2023/01/FlamingBytes-logos_transparent-9.png",
            "width": 60,
            "height": 60
        }
    },
    "author": {
        "@type": "Person",
        "name": "relentlesstorm",
        "url": "https://relentlesstorm.github.io/author/relentlesstorm/",
        "sameAs": []
    },
    "headline": "OpenZFS - A pooled storage file system",
    "url": "https://relentlesstorm.github.io/openzfs-a-pooled-storage-file-system/",
    "datePublished": "2022-03-16T00:00:00.000Z",
    "dateModified": "2023-01-03T21:42:23.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://images.unsplash.com/photo-1461360228754-6e81c478b882?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDF8fGZpbGUlMjBzeXN0ZW18ZW58MHx8fHwxNjcyNzgyMTAz&ixlib=rb-4.0.3&q=80&w=2000",
        "width": 2000,
        "height": 1328
    },
    "keywords": "Cloud Storage",
    "description": "OpenZFS\n\n\nThe OpenZFS project is an open source derivative of the Oracle ZFS project. OpenZFS is an outstanding storage platform that encompasses the functionality of traditional filesystems, volume managers, and more, with consistent reliability, functionality and performance across all distributions.\n\n\nSource1\n\nSource2\n\n\n\nZFS and ZFS Pooled Storage\n\n\nThe ZFS file system is a revolutionary new file system that fundamentally changes the way file systems are administered, with features and benefi",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://relentlesstorm.github.io/"
    }
}
    </script>

    <meta name="generator" content="Ghost 5.26" />
    <link rel="alternate" type="application/rss+xml" title="Flamingbytes" href="https://relentlesstorm.github.io/rss/" />
    
    <script defer src="https://cdn.jsdelivr.net/ghost/sodo-search@~1.1/umd/sodo-search.min.js" data-key="321a1d1aea33fd468f6e61f563" data-styles="https://cdn.jsdelivr.net/ghost/sodo-search@~1.1/umd/main.css" data-sodo-search="https://relentlesstorm.github.io/" crossorigin="anonymous"></script>
    <script defer src="/public/cards.min.js?v=6e3eba6684"></script>
    <link rel="stylesheet" type="text/css" href="/public/cards.min.css?v=6e3eba6684">
    <script defer src="/public/comment-counts.min.js?v=6e3eba6684" data-ghost-comments-counts-api="https://relentlesstorm.github.io/members/api/comments/counts/"></script>
    <style>.gh-head-logo img{max-height:100px;height:100%;}</style>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-B8PQ47L2H0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-B8PQ47L2H0');
</script><style>:root {--ghost-accent-color: #6a13ec;}</style>
</head>

<body class="post-template tag-cloud-storage is-head-left-logo has-serif-body">
<div class="gh-site">

    <header id="gh-head" class="gh-head gh-outer">
        <div class="gh-head-inner gh-inner">
            <div class="gh-head-brand">
                <div class="gh-head-brand-wrapper">
                    <a class="gh-head-logo" href="https://relentlesstorm.github.io">
                            Flamingbytes
                    </a>
                </div>
                <button class="gh-search gh-icon-btn" data-ghost-search><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" width="20" height="20"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg></button>
                <button class="gh-burger"></button>
            </div>

            <nav class="gh-head-menu">
                <ul class="nav">
    <li class="nav-home"><a href="https://relentlesstorm.github.io/">Home</a></li>
    <li class="nav-tags"><a href="https://relentlesstorm.github.io/tags/">Tags</a></li>
    <li class="nav-archive"><a href="https://relentlesstorm.github.io/archive/">Archive</a></li>
    <li class="nav-about"><a href="https://relentlesstorm.github.io/about/">About</a></li>
</ul>

            </nav>

            <div class="gh-head-actions">
                        <button class="gh-search gh-icon-btn" data-ghost-search><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2" width="20" height="20"><path stroke-linecap="round" stroke-linejoin="round" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg></button>
            </div>
        </div>
    </header>

    
<main class="gh-main">
        <article class="gh-article post tag-cloud-storage">

            <header class="gh-article-header gh-canvas">
                    <a class="gh-article-tag" href="https://relentlesstorm.github.io/tag/cloud-storage/">Cloud Storage</a>

                <h1 class="gh-article-title">OpenZFS - A pooled storage file system</h1>

                    <aside class="gh-article-sidebar">

        <div class="gh-author-image-list">
                <a class="gh-author-image" href="/author/relentlesstorm/">
                        <div class="gh-author-icon"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="64" height="64"><g fill="none" fill-rule="evenodd"><path d="M3.513 18.998C4.749 15.504 8.082 13 12 13s7.251 2.504 8.487 5.998C18.47 21.442 15.417 23 12 23s-6.47-1.558-8.487-4.002zM12 12c2.21 0 4-2.79 4-5s-1.79-4-4-4-4 1.79-4 4 1.79 5 4 5z" fill="#FFF"/></g></svg>
</div>
                </a>
        </div>

        <div class="gh-author-name-list">
                <h4 class="gh-author-name">
                    <a href="/author/relentlesstorm/">relentlesstorm</a>
                </h4>
                
        </div>

        <div class="gh-article-meta">
            <div class="gh-article-meta-inner">
                <time class="gh-article-date" datetime="2022-03-16">Mar 16, 2022</time>
                    <span class="gh-article-meta-sep"></span>
                    <span class="gh-article-length">9 min</span>
            </div>
        </div>

    </aside>


                    <figure class="gh-article-image">
        <img
            srcset="https://images.unsplash.com/photo-1461360228754-6e81c478b882?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDF8fGZpbGUlMjBzeXN0ZW18ZW58MHx8fHwxNjcyNzgyMTAz&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;300 300w,
                    https://images.unsplash.com/photo-1461360228754-6e81c478b882?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDF8fGZpbGUlMjBzeXN0ZW18ZW58MHx8fHwxNjcyNzgyMTAz&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;720 720w,
                    https://images.unsplash.com/photo-1461360228754-6e81c478b882?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDF8fGZpbGUlMjBzeXN0ZW18ZW58MHx8fHwxNjcyNzgyMTAz&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;960 960w,
                    https://images.unsplash.com/photo-1461360228754-6e81c478b882?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDF8fGZpbGUlMjBzeXN0ZW18ZW58MHx8fHwxNjcyNzgyMTAz&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;1200 1200w,
                    https://images.unsplash.com/photo-1461360228754-6e81c478b882?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDF8fGZpbGUlMjBzeXN0ZW18ZW58MHx8fHwxNjcyNzgyMTAz&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000 2000w"
            sizes="(max-width: 1200px) 100vw, 1200px"
            src="https://images.unsplash.com/photo-1461360228754-6e81c478b882?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDF8fGZpbGUlMjBzeXN0ZW18ZW58MHx8fHwxNjcyNzgyMTAz&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;1200"
            alt="OpenZFS - A pooled storage file system"
        >
            <figcaption>Photo by <a href="https://unsplash.com/fr/@iammrcup?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit">Mr Cup / Fabien Barral</a> / <a href="https://unsplash.com/?utm_source=ghost&utm_medium=referral&utm_campaign=api-credit">Unsplash</a></figcaption>
    </figure>
            </header>

            <section class="gh-content gh-canvas">
                <aside class="gh-sidebar"><div class="gh-toc"></div></aside> 
                <!--kg-card-begin: markdown--><h2 id="openzfs">OpenZFS</h2>
<p>The OpenZFS project is an open source derivative of the Oracle ZFS project. OpenZFS is an outstanding storage platform that encompasses the functionality of traditional filesystems, volume managers, and more, with consistent reliability, functionality and performance across all distributions.</p>
<p><a href="https://en.wikipedia.org/wiki/OpenZFS">Source1</a><br>
<a href="https://openzfs.github.io/openzfs-docs/Project%20and%20Community/FAQ.html#what-is-openzfs">Source2</a></p>
<h2 id="zfs-and-zfs-pooled-storage">ZFS and ZFS Pooled Storage</h2>
<p>The ZFS file system is a revolutionary new file system that fundamentally changes the way file systems are administered, with features and benefits not found in any other file system available today. ZFS is robust, scalable, and easy to administer.</p>
<p>ZFS uses the concept of storage pools to manage physical storage. Historically, file systems were constructed on top of a single physical device. To address multiple devices and provide for data redundancy, the concept of a volume manager was introduced to provide a representation of a single device so that file systems would not need to be modified to take advantage of multiple devices. This design added another layer of complexity and ultimately prevented certain file system advances because the file system had no control over the physical placement of data on the virtualized volumes.</p>
<p>ZFS eliminates volume management altogether. Instead of forcing you to create virtualized volumes, ZFS aggregates devices into a storage pool. The storage pool describes the physical characteristics of the storage (device layout, data redundancy, and so on) and acts as an arbitrary data store from which file systems can be created. File systems are no longer constrained to individual devices, allowing them to share disk space with all file systems in the pool. You no longer need to predetermine the size of a file system, as file systems grow automatically within the disk space allocated to the storage pool. When new storage is added, all file systems within the pool can immediately use the additional disk space without additional work. In many ways, the storage pool works similarly to a virtual memory system: When a memory DIMM is added to a system, the operating system doesn't force you to run commands to configure the memory and assign it to individual processes. All processes on the system automatically use the additional memory.</p>
<p><a href="https://docs.oracle.com/cd/E19253-01/819-5461/zfsover-2/index.html">Source</a></p>
<h2 id="install-zfs-on-centos">Install ZFS on CentOS</h2>
<p>ZFS is not included by default in CentOS. We will learn how to install it on CentOS 7.9 in this post.</p>
<ol>
<li>
<p>Add ZFS repository</p>
<pre><code class="language-shell">$ cat /etc/centos-release
CentOS Linux release 7.9.2009 (Core)

$ yum install https://zfsonlinux.org/epel/zfs-release.el7_9.noarch.rpm -y
</code></pre>
</li>
<li>
<p>DKMS vs. kABI</p>
<p>DKMS and kABI are the two methods ZFS module can be loaded into the kernel. We are going to use kABI since it doesn't require kernel re-compilation in case of kernel update. We can enable it by editing the ZFS repository as below.</p>
<pre><code class="language-shell">$ cat /etc/yum.repos.d/zfs.repo
[zfs]
name=OpenZFS for EL7 - dkms
baseurl=http://download.zfsonlinux.org/epel/7.9/$basearch/
enabled=1
metadata_expire=7d
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux

[zfs-kmod]
name=OpenZFS for EL7 - kmod
baseurl=http://download.zfsonlinux.org/epel/7.9/kmod/$basearch/
enabled=0
metadata_expire=7d
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux

[zfs-source]
name=OpenZFS for EL7 - Source
baseurl=http://download.zfsonlinux.org/epel/7.9/SRPMS/
enabled=0
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux

[zfs-next]
name=OpenZFS for EL7 - dkms - Next upcoming version
baseurl=http://download.zfsonlinux.org/epel-next/7.9/$basearch/
enabled=0
metadata_expire=7d
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux

[zfs-testing]
name=OpenZFS for EL7 - dkms - Testing
baseurl=http://download.zfsonlinux.org/epel-testing/7.9/$basearch/
enabled=0
metadata_expire=7d
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux

[zfs-testing-kmod]
name=OpenZFS for EL7 - kmod - Testing
baseurl=http://download.zfsonlinux.org/epel-testing/7.9/kmod/$basearch/
enabled=0
metadata_expire=7d
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux

[zfs-testing-source]
name=OpenZFS for EL7 - Testing Source
baseurl=http://download.zfsonlinux.org/epel-testing/7.9/SRPMS/
enabled=0
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux
</code></pre>
<p>We can disable DKMS and enable KABI by editing the <em>enable=</em> in the following two sections.</p>
<pre><code class="language-shell">$ vim /etc/yum.repos.d/zfs.repo
[zfs]
name=OpenZFS for EL7 - dkms
baseurl=http://download.zfsonlinux.org/epel/7.9/$basearch/
enabled=0
metadata_expire=7d
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux

[zfs-kmod]
name=OpenZFS for EL7 - kmod
baseurl=http://download.zfsonlinux.org/epel/7.9/kmod/$basearch/
enabled=1
metadata_expire=7d
gpgcheck=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-zfsonlinux
</code></pre>
</li>
<li>
<p>Install ZFS</p>
<p>Install ZFS using the following command:</p>
<pre><code class="language-shell">$ yum install zfs -y
[..]
Installed:
zfs.x86_64 0:2.0.7-1.el7

Dependency Installed:
kmod-zfs.x86_64 0:2.0.7-1.el7      libnvpair3.x86_64 0:2.0.7-1.el7     libuutil3.x86_64 0:2.0.7-1.el7     libzfs4.x86_64 0:2.0.7-1.el7     libzpool4.x86_64 0:2.0.7-1.el7     lm_sensors-libs.x86_64 0:3.4.0-8.20160601gitf9185e5.el7
sysstat.x86_64 0:10.1.5-19.el7
</code></pre>
<p>Reboot the system to load zfs module:</p>
<pre><code class="language-shell">$ reboot
$ lsmod | grep zfs
</code></pre>
<p>Use the following command to load the ZFS kernel module if it's not loaded after reboot:</p>
<pre><code class="language-shell">$ modprobe zfs

$ lsmod | grep zfs
zfs                  4224878  0
zunicode              331170  1 zfs
zzstd                 460780  1 zfs
zlua                  151526  1 zfs
zcommon                94285  1 zfs
znvpair                94388  2 zfs,zcommon
zavl                   15698  1 zfs
icp                   301775  1 zfs
spl                    96750  6 icp,zfs,zavl,zzstd,zcommon,znvpair

$ modinfo zfs
filename:       /lib/modules/3.10.0-1160.11.1.el7.x86_64/weak-updates/zfs/zfs/zfs.ko
version:        2.0.7-1
license:        CDDL
author:         OpenZFS
description:    ZFS
alias:          devname:zfs
alias:          char-major-10-249
retpoline:      Y
rhelversion:    7.9
srcversion:     CDFB8A7F2D3EE43324CF460
depends:        spl,znvpair,icp,zlua,zzstd,zunicode,zcommon,zavl
vermagic:       3.10.0-1160.49.1.el7.x86_64 SMP mod_unload modversions
[..]

$ zfs version
zfs-2.0.7-1
zfs-kmod-2.0.7-1
</code></pre>
</li>
</ol>
<h2 id="manage-zfs-storage-pool-and-file-system">Manage ZFS storage pool and file system</h2>
<ul>
<li>
<p>Create ZFS storage pool</p>
<pre><code class="language-shell">$ zpool create zpooldemo /dev/sdb
</code></pre>
</li>
<li>
<p>Add disk to ZFS storage pool</p>
<pre><code class="language-shell">$ zpool add zpooldemo /dev/sdc
</code></pre>
</li>
<li>
<p>Check ZFS pool status</p>
<pre><code class="language-shell">$ zpool list
NAME        SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP    HEALTH  ALTROOT
zpooldemo   119G   174K   119G        -         -     0%     0%  1.00x    ONLINE  -

$ zpool status
pool: zpooldemo
state: ONLINE
config:

    NAME        STATE     READ WRITE CKSUM
    zpooldemo   ONLINE       0     0     0
    sdb       ONLINE       0     0     0
    sdc       ONLINE       0     0     0

errors: No known data errors
</code></pre>
</li>
<li>
<p>Create ZFS file system</p>
<p>When you create a pool, a ZFS file system is created and mounted automatically. The whole file system space can be used as needed.</p>
<pre><code class="language-shell">$ mount | egrep &quot;zfs&quot;
zpooldemo on /zpooldemo type zfs (rw,xattr,noacl)

$ df -h | egrep &quot;Filesystem|zpool&quot;
Filesystem      Size  Used Avail Use% Mounted on
zpooldemo       116G  128K  116G   1% /zpooldemo

$ touch /zpooldemo/testfile
$ ls -la /zpooldemo/
total 6
drwxr-xr-x   3 root root    4 Mar 17 22:49 .
dr-xr-xr-x. 19 root root 4096 Mar 17 22:37 ..
-rw-r--r--   1 root root    0 Mar 17 22:49 testfile
</code></pre>
<p>Within a pool, additional file systems can be created. The new create file systems allow users to manage different sets of data within the same pool.</p>
<pre><code class="language-shell">$ zfs create zpooldemo/zfsdemo

$ mount | egrep &quot;zfs&quot;
zpooldemo on /zpooldemo type zfs (rw,xattr,noacl)
zpooldemo/zfsdemo on /zpooldemo/zfsdemo type zfs (rw,xattr,noacl)

$ df -h | egrep &quot;Filesystem|zpool&quot;
Filesystem         Size  Used Avail Use% Mounted on
zpooldemo          116G  128K  116G   1% /zpooldemo
zpooldemo/zfsdemo  116G  128K  116G   1% /zpooldemo/zfsdemo
</code></pre>
</li>
<li>
<p>Set ZFS file system properties</p>
<p>The file system property can be set when the ZFS is created.</p>
<pre><code class="language-shell">$ zfs create -o atime=off zpooldemo/zfsdemo
$ mount | grep zfs
zpooldemo on /zpooldemo type zfs (rw,xattr,noacl)
zpooldemo/zfsdemo on /zpooldemo/zfsdemo type zfs (rw,noatime,xattr,noacl)
</code></pre>
<p>The storage pool and file system properties can be retrieved as below.</p>
<pre><code class="language-shell">$ zpool get all zpooldemo
NAME       PROPERTY                       VALUE                          SOURCE
zpooldemo  size                           59.5G                          -
zpooldemo  capacity                       0%                             -
zpooldemo  altroot                        -                              default
zpooldemo  health                         ONLINE                         -
zpooldemo  guid                           11167503015555961412           -
zpooldemo  version                        -                              default
zpooldemo  bootfs                         -                              default
zpooldemo  delegation                     on                             default
zpooldemo  autoreplace                    off                            default
zpooldemo  cachefile                      -                              default
zpooldemo  failmode                       wait                           default
zpooldemo  listsnapshots                  off                            default
zpooldemo  autoexpand                     off                            default
zpooldemo  dedupratio                     1.00x                          -
zpooldemo  free                           59.5G                          -
zpooldemo  allocated                      106K                           -
zpooldemo  readonly                       off                            -
zpooldemo  ashift                         0                              default
zpooldemo  comment                        -                              default
zpooldemo  expandsize                     -                              -
zpooldemo  freeing                        0                              -
zpooldemo  fragmentation                  0%                             -
zpooldemo  leaked                         0                              -
zpooldemo  multihost                      off                            default
zpooldemo  checkpoint                     -                              -
zpooldemo  load_guid                      10842965729770643306           -
zpooldemo  autotrim                       off                            default
zpooldemo  feature@async_destroy          enabled                        local
zpooldemo  feature@empty_bpobj            enabled                        local
zpooldemo  feature@lz4_compress           active                         local
zpooldemo  feature@multi_vdev_crash_dump  enabled                        local
zpooldemo  feature@spacemap_histogram     active                         local
zpooldemo  feature@enabled_txg            active                         local
zpooldemo  feature@hole_birth             active                         local
zpooldemo  feature@extensible_dataset     active                         local
zpooldemo  feature@embedded_data          active                         local
zpooldemo  feature@bookmarks              enabled                        local
zpooldemo  feature@filesystem_limits      enabled                        local
zpooldemo  feature@large_blocks           enabled                        local
zpooldemo  feature@large_dnode            enabled                        local
zpooldemo  feature@sha512                 enabled                        local
zpooldemo  feature@skein                  enabled                        local
zpooldemo  feature@edonr                  enabled                        local
zpooldemo  feature@userobj_accounting     active                         local
zpooldemo  feature@encryption             enabled                        local
zpooldemo  feature@project_quota          active                         local
zpooldemo  feature@device_removal         enabled                        local
zpooldemo  feature@obsolete_counts        enabled                        local
zpooldemo  feature@zpool_checkpoint       enabled                        local
zpooldemo  feature@spacemap_v2            active                         local
zpooldemo  feature@allocation_classes     enabled                        local
zpooldemo  feature@resilver_defer         enabled                        local
zpooldemo  feature@bookmark_v2            enabled                        local
zpooldemo  feature@redaction_bookmarks    enabled                        local
zpooldemo  feature@redacted_datasets      enabled                        local
zpooldemo  feature@bookmark_written       enabled                        local
zpooldemo  feature@log_spacemap           active                         local
zpooldemo  feature@livelist               enabled                        local
zpooldemo  feature@device_rebuild         enabled                        local
zpooldemo  feature@zstd_compress          enabled                        local

$ zfs get all zpooldemo/zfsdemo
NAME               PROPERTY              VALUE                  SOURCE
zpooldemo/zfsdemo  type                  filesystem             -
zpooldemo/zfsdemo  creation              Thu Mar 17 23:00 2022  -
zpooldemo/zfsdemo  used                  24K                    -
zpooldemo/zfsdemo  available             57.6G                  -
zpooldemo/zfsdemo  referenced            24K                    -
zpooldemo/zfsdemo  compressratio         1.00x                  -
zpooldemo/zfsdemo  mounted               yes                    -
zpooldemo/zfsdemo  quota                 none                   default
zpooldemo/zfsdemo  reservation           none                   default
zpooldemo/zfsdemo  recordsize            128K                   default
zpooldemo/zfsdemo  mountpoint            /zpooldemo/zfsdemo     default
zpooldemo/zfsdemo  sharenfs              off                    default
zpooldemo/zfsdemo  checksum              on                     default
zpooldemo/zfsdemo  compression           off                    default
zpooldemo/zfsdemo  atime                 off                    local
zpooldemo/zfsdemo  devices               on                     default
zpooldemo/zfsdemo  exec                  on                     default
zpooldemo/zfsdemo  setuid                on                     default
zpooldemo/zfsdemo  readonly              off                    default
zpooldemo/zfsdemo  zoned                 off                    default
zpooldemo/zfsdemo  snapdir               hidden                 default
zpooldemo/zfsdemo  aclmode               discard                default
zpooldemo/zfsdemo  aclinherit            restricted             default
zpooldemo/zfsdemo  createtxg             20                     -
zpooldemo/zfsdemo  canmount              on                     default
zpooldemo/zfsdemo  xattr                 on                     default
zpooldemo/zfsdemo  copies                1                      default
zpooldemo/zfsdemo  version               5                      -
zpooldemo/zfsdemo  utf8only              off                    -
zpooldemo/zfsdemo  normalization         none                   -
zpooldemo/zfsdemo  casesensitivity       sensitive              -
zpooldemo/zfsdemo  vscan                 off                    default
zpooldemo/zfsdemo  nbmand                off                    default
zpooldemo/zfsdemo  sharesmb              off                    default
zpooldemo/zfsdemo  refquota              none                   default
zpooldemo/zfsdemo  refreservation        none                   default
zpooldemo/zfsdemo  guid                  10461278007032944398   -
zpooldemo/zfsdemo  primarycache          all                    default
zpooldemo/zfsdemo  secondarycache        all                    default
zpooldemo/zfsdemo  usedbysnapshots       0B                     -
zpooldemo/zfsdemo  usedbydataset         24K                    -
zpooldemo/zfsdemo  usedbychildren        0B                     -
zpooldemo/zfsdemo  usedbyrefreservation  0B                     -
zpooldemo/zfsdemo  logbias               latency                default
zpooldemo/zfsdemo  objsetid              136                    -
zpooldemo/zfsdemo  dedup                 off                    default
zpooldemo/zfsdemo  mlslabel              none                   default
zpooldemo/zfsdemo  sync                  standard               default
zpooldemo/zfsdemo  dnodesize             legacy                 default
zpooldemo/zfsdemo  refcompressratio      1.00x                  -
zpooldemo/zfsdemo  written               24K                    -
zpooldemo/zfsdemo  logicalused           12K                    -
zpooldemo/zfsdemo  logicalreferenced     12K                    -
zpooldemo/zfsdemo  volmode               default                default
zpooldemo/zfsdemo  filesystem_limit      none                   default
zpooldemo/zfsdemo  snapshot_limit        none                   default
zpooldemo/zfsdemo  filesystem_count      none                   default
zpooldemo/zfsdemo  snapshot_count        none                   default
zpooldemo/zfsdemo  snapdev               hidden                 default
zpooldemo/zfsdemo  acltype               off                    default
zpooldemo/zfsdemo  context               none                   default
zpooldemo/zfsdemo  fscontext             none                   default
zpooldemo/zfsdemo  defcontext            none                   default
zpooldemo/zfsdemo  rootcontext           none                   default
zpooldemo/zfsdemo  relatime              off                    default
zpooldemo/zfsdemo  redundant_metadata    all                    default
zpooldemo/zfsdemo  overlay               on                     default
zpooldemo/zfsdemo  encryption            off                    default
zpooldemo/zfsdemo  keylocation           none                   default
zpooldemo/zfsdemo  keyformat             none                   default
zpooldemo/zfsdemo  pbkdf2iters           0                      default
zpooldemo/zfsdemo  special_small_blocks  0                      default
</code></pre>
<p><em>zfs set</em> command can be used to set any dataset property.</p>
<pre><code class="language-shell">$ zfs set checksum=off zpooldemo/zfsdemo
</code></pre>
<p><em>zfs get</em> command can be used to retrieve any dataset property.</p>
<pre><code class="language-shell">$ zfs get checksum zpooldemo
NAME       PROPERTY  VALUE      SOURCE
zpooldemo  checksum  on         default

$ zfs get checksum zpooldemo/zfsdemo
NAME               PROPERTY  VALUE      SOURCE
zpooldemo/zfsdemo  checksum  off        local
</code></pre>
</li>
<li>
<p>Destroy ZFS storage pool and file system</p>
<pre><code class="language-shell">$ zfs list
NAME                USED  AVAIL     REFER  MOUNTPOINT
zpooldemo           194K   115G       25K  /zpooldemo
zpooldemo/zfsdemo    24K   115G       24K  /zpooldemo/zfsdemo

$ zfs destroy zpooldemo/zfsdemo

$ zfs list
NAME        USED  AVAIL     REFER  MOUNTPOINT
zpooldemo   169K   115G       25K  /zpooldemo
</code></pre>
<pre><code class="language-shell">$ zpool destroy zpooldemo
$ zpool list
no pools available
</code></pre>
</li>
</ul>
<h2 id="kernel-compatibility">Kernel compatibility</h2>
<p>When to install zfs on CentOS, it will check if the already installed kernel version matches the specified the release version. In the following example, the required kernel 3.10.0-1160 will be installed automatically during zfs-release.el7_9 installation.</p>
<pre><code class="language-shell">$ yum install https://zfsonlinux.org/epel/zfs-release.el7_9.noarch.rpm -y
$ yum install zfs -y
Installed:
kernel.x86_64 0:3.10.0-1160.59.1.el7                                                                                       
zfs.x86_64 0:2.0.7-1.el7

Dependency Installed:
kmod-zfs.x86_64 0:2.0.7-1.el7                 
libnvpair3.x86_64 0:2.0.7-1.el7                 
libuutil3.x86_64 0:2.0.7-1.el7                 
libzfs4.x86_64 0:2.0.7-1.el7                 
libzpool4.x86_64 0:2.0.7-1.el7

$ reboot
$ uname -r
3.10.0-1160.59.1.el7.x86_64

$ lsmod  |  grep zfs
$ modprobe zfs
$ lsmod  |  grep zfs
zfs                  4224878  0
zunicode              331170  1 zfs
zzstd                 460780  1 zfs
zlua                  151526  1 zfs
zcommon                94285  1 zfs
znvpair                94388  2 zfs,zcommon
zavl                   15698  1 zfs
icp                   301775  1 zfs
spl                    96750  6 icp,zfs,zavl,zzstd,zcommon,znvpair
$ zfs version
zfs-2.0.7-1
zfs-kmod-2.0.7-1
</code></pre>
<h2 id="uninstall-zfs">Uninstall ZFS</h2>
<p>Remove the installed rpms and remove the repository as below.</p>
<pre><code class="language-shell">$ rpm -ev &lt;pkg-rpm-name&gt;
$ yum remove zfs-release
</code></pre>
<h2 id="reference">Reference</h2>
<ul>
<li><a href="https://en.wikipedia.org/wiki/OpenZFS">https://en.wikipedia.org/wiki/OpenZFS</a></li>
<li><a href="https://openzfs.org/wiki/Main_Page">https://openzfs.org/wiki/Main_Page</a></li>
<li><a href="https://openzfs.github.io/openzfs-docs/index.html">https://openzfs.github.io/openzfs-docs/index.html</a></li>
<li><a href="https://docs.oracle.com/cd/E19253-01/819-5461/index.html">https://docs.oracle.com/cd/E19253-01/819-5461/index.html</a></li>
<li><a href="https://www.symmcom.com/docs/how-tos/storages/how-to-install-zfs-on-centos-7">https://www.symmcom.com/docs/how-tos/storages/how-to-install-zfs-on-centos-7</a></li>
<li><a href="https://zfsonlinux.org/">https://zfsonlinux.org/</a></li>
</ul>
<!--kg-card-end: markdown-->
            </section>

        </article>

                <div class="gh-read-next gh-canvas">
                <section class="gh-pagehead">
                    <h4 class="gh-pagehead-title">Read next</h4>
                </section>

                <div class="gh-topic gh-topic-grid">
                    <div class="gh-topic-content">
                            <article class="gh-card post">
    <a class="gh-card-link" href="/understanding-azure-disk-bursting/">
            <figure class="gh-card-image">
                <img
                    srcset="https://images.unsplash.com/photo-1615293889204-6db03c596147?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDR8fGhhcmRkaXNrfGVufDB8fHx8MTY3Mjc3NzYzNA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;300 300w,
                            https://images.unsplash.com/photo-1615293889204-6db03c596147?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDR8fGhhcmRkaXNrfGVufDB8fHx8MTY3Mjc3NzYzNA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;720 720w,
                            https://images.unsplash.com/photo-1615293889204-6db03c596147?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDR8fGhhcmRkaXNrfGVufDB8fHx8MTY3Mjc3NzYzNA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;960 960w,
                            https://images.unsplash.com/photo-1615293889204-6db03c596147?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDR8fGhhcmRkaXNrfGVufDB8fHx8MTY3Mjc3NzYzNA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;1200 1200w,
                            https://images.unsplash.com/photo-1615293889204-6db03c596147?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDR8fGhhcmRkaXNrfGVufDB8fHx8MTY3Mjc3NzYzNA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000 2000w"
                    sizes="(max-width: 1200px) 100vw, 1200px"
                    src="https://images.unsplash.com/photo-1615293889204-6db03c596147?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDR8fGhhcmRkaXNrfGVufDB8fHx8MTY3Mjc3NzYzNA&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;720"
                    alt="Understanding Azure disk bursting"
                >
            </figure>

        <div class="gh-card-wrapper">
            <header class="gh-card-header">
                <h3 class="gh-card-title">Understanding Azure disk bursting</h3>
            </header>

                    <div class="gh-card-excerpt">Currently, there are two managed disk types that can burst, premium SSDs, and standard SSDs. Other disk types cannot currently burst. There are two models of bursting for disks:


An on-demand bursting model, where the disk bursts whenever its needs exceed its current capacity. This model incurs additional charges anytime</div>

            <footer class="gh-card-footer">
                <span class="gh-card-author">relentlesstorm</span>
                <time class="gh-card-date" datetime="2022-09-15">Sep 15, 2022</time>
                    <script
    data-ghost-comment-count="63b48f561527a00d97449cbf"
    data-ghost-comment-count-empty=""
    data-ghost-comment-count-singular="comment"
    data-ghost-comment-count-plural="comments"
    data-ghost-comment-count-tag="span"
    data-ghost-comment-count-class-name="gh-card-comments"
    data-ghost-comment-count-autowrap="true"
>
</script>
            </footer>
        </div>
    </a>
</article>                            <article class="gh-card post">
    <a class="gh-card-link" href="/understanding-rpo-and-rto/">
            <figure class="gh-card-image">
                <img
                    srcset="https://images.unsplash.com/photo-1586974175094-0a7259238613?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDJ8fHJlY292ZXJ5fGVufDB8fHx8MTY3Mjc3OTU4Ng&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;300 300w,
                            https://images.unsplash.com/photo-1586974175094-0a7259238613?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDJ8fHJlY292ZXJ5fGVufDB8fHx8MTY3Mjc3OTU4Ng&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;720 720w,
                            https://images.unsplash.com/photo-1586974175094-0a7259238613?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDJ8fHJlY292ZXJ5fGVufDB8fHx8MTY3Mjc3OTU4Ng&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;960 960w,
                            https://images.unsplash.com/photo-1586974175094-0a7259238613?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDJ8fHJlY292ZXJ5fGVufDB8fHx8MTY3Mjc3OTU4Ng&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;1200 1200w,
                            https://images.unsplash.com/photo-1586974175094-0a7259238613?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDJ8fHJlY292ZXJ5fGVufDB8fHx8MTY3Mjc3OTU4Ng&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000 2000w"
                    sizes="(max-width: 1200px) 100vw, 1200px"
                    src="https://images.unsplash.com/photo-1586974175094-0a7259238613?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDJ8fHJlY292ZXJ5fGVufDB8fHx8MTY3Mjc3OTU4Ng&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;720"
                    alt="Understanding RPO and RTO"
                >
            </figure>

        <div class="gh-card-wrapper">
            <header class="gh-card-header">
                <h3 class="gh-card-title">Understanding RPO and RTO</h3>
            </header>

                    <div class="gh-card-excerpt">The disasters could occur unexpectedly and it could take down the whole data center in an application region. In the real world, a well designed disaster recovery solution would help restore the applications and related data at the time of disaster.


There are two critical metrics to measure how timely</div>

            <footer class="gh-card-footer">
                <span class="gh-card-author">relentlesstorm</span>
                <time class="gh-card-date" datetime="2022-05-01">May 1, 2022</time>
                    <script
    data-ghost-comment-count="63b497051527a00d97449dca"
    data-ghost-comment-count-empty=""
    data-ghost-comment-count-singular="comment"
    data-ghost-comment-count-plural="comments"
    data-ghost-comment-count-tag="span"
    data-ghost-comment-count-class-name="gh-card-comments"
    data-ghost-comment-count-autowrap="true"
>
</script>
            </footer>
        </div>
    </a>
</article>                            <article class="gh-card post">
    <a class="gh-card-link" href="/access-a-sharedv4-volume-outside-of-a-portwrox-cluster/">
            <figure class="gh-card-image">
                <img
                    srcset="https://images.unsplash.com/photo-1614902333346-d0caef873a11?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDIzfHxuZnN8ZW58MHx8fHwxNjcyNzc4ODEx&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;300 300w,
                            https://images.unsplash.com/photo-1614902333346-d0caef873a11?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDIzfHxuZnN8ZW58MHx8fHwxNjcyNzc4ODEx&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;720 720w,
                            https://images.unsplash.com/photo-1614902333346-d0caef873a11?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDIzfHxuZnN8ZW58MHx8fHwxNjcyNzc4ODEx&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;960 960w,
                            https://images.unsplash.com/photo-1614902333346-d0caef873a11?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDIzfHxuZnN8ZW58MHx8fHwxNjcyNzc4ODEx&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;1200 1200w,
                            https://images.unsplash.com/photo-1614902333346-d0caef873a11?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDIzfHxuZnN8ZW58MHx8fHwxNjcyNzc4ODEx&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;2000 2000w"
                    sizes="(max-width: 1200px) 100vw, 1200px"
                    src="https://images.unsplash.com/photo-1614902333346-d0caef873a11?crop&#x3D;entropy&amp;cs&#x3D;tinysrgb&amp;fit&#x3D;max&amp;fm&#x3D;jpg&amp;ixid&#x3D;MnwxMTc3M3wwfDF8c2VhcmNofDIzfHxuZnN8ZW58MHx8fHwxNjcyNzc4ODEx&amp;ixlib&#x3D;rb-4.0.3&amp;q&#x3D;80&amp;w&#x3D;720"
                    alt="Access a sharedv4 volume outside of a Portwrox cluster"
                >
            </figure>

        <div class="gh-card-wrapper">
            <header class="gh-card-header">
                <h3 class="gh-card-title">Access a sharedv4 volume outside of a Portwrox cluster</h3>
            </header>

                    <div class="gh-card-excerpt">To access a sharedv4 volume outside of the Portworx cluster, add the allow_ips label to the volume you wish to export, specifying a semi-colon separated list of IP addresses of non-Portworx nodes you wish to mount your sharedv4 volume to:


$ /opt/pwx/bin/pxctl -j volume create datavol --sharedv4</div>

            <footer class="gh-card-footer">
                <span class="gh-card-author">relentlesstorm</span>
                <time class="gh-card-date" datetime="2022-04-20">Apr 20, 2022</time>
                    <script
    data-ghost-comment-count="63b49f591527a00d97449e25"
    data-ghost-comment-count-empty=""
    data-ghost-comment-count-singular="comment"
    data-ghost-comment-count-plural="comments"
    data-ghost-comment-count-tag="span"
    data-ghost-comment-count-class-name="gh-card-comments"
    data-ghost-comment-count-autowrap="true"
>
</script>
            </footer>
        </div>
    </a>
</article>                    </div>
                </div>
            </div>

    
        <!-- ghost native comments
                    <div class="gh-comments gh-read-next gh-canvas">
            <section class="gh-pagehead">
                <h4 class="gh-pagehead-title">Comments (<script
    data-ghost-comment-count="63b4a0e71527a00d97449e6b"
    data-ghost-comment-count-empty="0"
    data-ghost-comment-count-singular=""
    data-ghost-comment-count-plural=""
    data-ghost-comment-count-tag="span"
    data-ghost-comment-count-class-name=""
    data-ghost-comment-count-autowrap="true"
>
</script>)</h3>
            </section>
            
        <script defer src="https://cdn.jsdelivr.net/ghost/comments-ui@~0.12/umd/comments-ui.min.js" data-ghost-comments="https://relentlesstorm.github.io/" data-api="https://relentlesstorm.github.io/ghost/api/content/" data-admin="https://relentlesstorm.github.io/ghost/" data-key="321a1d1aea33fd468f6e61f563" data-styles="https://cdn.jsdelivr.net/ghost/comments-ui@~0.12/umd/main.css" data-title="" data-count="false" data-post-id="63b4a0e71527a00d97449e6b" data-sentry-dsn="" data-color-scheme="auto" data-avatar-saturation="60" data-accent-color="#6a13ec" data-app-version="0.12" data-comments-enabled="all" data-publication="Flamingbytes" crossorigin="anonymous"></script>
    
        </div>
        -->

        <!-- disqus comments 
        <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
        this.page.url = "https://relentlesstorm.github.io/openzfs-a-pooled-storage-file-system/";
        this.page.identifier = "ghost-63b4a0e71527a00d97449e6b"
    };
    (function() {
    var d = document, s = d.createElement('script');
    s.src = 'https://www-flamingbytes-com.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();
</script>
-->

</main>

    <footer class="gh-foot gh-outer">
        <div class="gh-foot-inner gh-inner">

            <!--<nav class="gh-foot-menu">
                <<ul class="nav">
    <li class="nav-sign-up"><a href="#/portal/">Sign up</a></li>
</ul>

            </nav>-->

            <div class="gh-copyright">
                    Flamingbytes © 2023. Powered by <a href="https://ghost.org/" target="_blank" rel="noopener">Ghost</a>
            </div>
        </div>
    </footer>

</div>

    <div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <div class="pswp__bg"></div>

    <div class="pswp__scroll-wrap">
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>
<script src="/assets/built/main.min.js?v=6e3eba6684"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.12.3/tocbot.min.js"></script>

<script>
    tocbot.init({
        // Where to render the table of contents.
        tocSelector: '.gh-toc',
        // Where to grab the headings to build the table of contents.
        contentSelector: '.gh-content',
        // Which headings to grab inside of the contentSelector element.
        headingSelector: 'h1, h2, h3, h4',
        // Ensure correct positioning
        hasInnerContainers: true,
    });
</script>



</body>

</html>
